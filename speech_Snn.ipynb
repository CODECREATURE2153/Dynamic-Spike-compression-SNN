{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please download speech_commands_v0.02.tar.gz from http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz and extract to 'speech_commands_v0.02'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "MFCC.__init__() got an unexpected keyword argument 'n_fft'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 69\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mfcc\u001b[38;5;241m.\u001b[39mflatten(), label  \u001b[38;5;66;03m# Shape: [13 * 100]\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Load datasets\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mSpeechCommandsDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m SpeechCommandsDataset(train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     71\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[2], line 37\u001b[0m, in \u001b[0;36mSpeechCommandsDataset.__init__\u001b[1;34m(self, root, train, target_words)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain \u001b[38;5;241m=\u001b[39m train\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_words \u001b[38;5;241m=\u001b[39m target_words\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m \u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMFCC\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_mfcc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m13\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m160\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mTypeError\u001b[0m: MFCC.__init__() got an unexpected keyword argument 'n_fft'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# baseline_snn_speech_commands.py\n",
    "# Baseline SNN for Google Speech Commands v0.02\n",
    "# Updated: April 26, 2025\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import snntorch as snn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from snntorch import surrogate\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "num_steps = 100  # 1 second at 10 ms frames\n",
    "num_inputs = 13 * 100  # 13 MFCCs, 100 frames\n",
    "num_hidden = 100\n",
    "num_outputs = 10  # 10 command words\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 15\n",
    "patience = 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Check dataset\n",
    "dataset_dir = \"speech_commands_v0.02\"\n",
    "if not os.path.exists(dataset_dir):\n",
    "    print(\"Please download speech_commands_v0.02.tar.gz from http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz and extract to 'speech_commands_v0.02'\")\n",
    "    exit()\n",
    "\n",
    "# Custom Dataset for Google Speech Commands\n",
    "class SpeechCommandsDataset(Dataset):\n",
    "    def __init__(self, root=\"speech_commands_v0.02\", train=True, target_words=[\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"]):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.target_words = target_words\n",
    "        self.transform = torchaudio.transforms.MFCC(sample_rate=16000, n_mfcc=13, n_fft=400, hop_length=160, f_min=20, f_max=4000)\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        split = \"train\" if train else \"test\"\n",
    "        for word in os.listdir(root):\n",
    "            if word in target_words:\n",
    "                word_dir = os.path.join(root, word)\n",
    "                for file in os.listdir(word_dir):\n",
    "                    if file.endswith(\".wav\"):\n",
    "                        file_path = os.path.join(word_dir, file)\n",
    "                        label = target_words.index(word)\n",
    "                        self.data.append(file_path)\n",
    "                        self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.data[idx], self.labels[idx]\n",
    "        waveform, sample_rate = torchaudio.load(file_path)\n",
    "        if sample_rate != 16000:\n",
    "            resampler = torchaudio.transforms.Resample(sample_rate, 16000)\n",
    "            waveform = resampler(waveform)\n",
    "        mfcc = self.transform(waveform)  # Shape: [13, num_frames]\n",
    "        num_frames = mfcc.shape[1]\n",
    "        if num_frames < 100:\n",
    "            mfcc = torch.nn.functional.pad(mfcc, (0, 100 - num_frames))\n",
    "        else:\n",
    "            mfcc = mfcc[:, :100]\n",
    "        return mfcc.flatten(), label  # Shape: [13 * 100]\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = SpeechCommandsDataset(train=True)\n",
    "test_dataset = SpeechCommandsDataset(train=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Surrogate gradient\n",
    "spike_grad = surrogate.fast_sigmoid(slope=25)\n",
    "\n",
    "# Baseline SNN\n",
    "class BaselineSNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lif1 = snn.Leaky(beta=0.9, spike_grad=spike_grad)\n",
    "        self.lif2 = snn.Leaky(beta=0.9, spike_grad=spike_grad)\n",
    "        for layer in [self.fc1, self.fc2]:\n",
    "            nn.init.xavier_uniform_(layer.weight, gain=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(1)\n",
    "        mem1, mem2 = self.lif1.init_leaky(), self.lif2.init_leaky()\n",
    "        spk1_rec, spk2_rec = [], []\n",
    "        for step in range(num_steps):\n",
    "            cur1 = self.fc1(x[step])\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk1_rec.append(spk1)\n",
    "            spk2_rec.append(spk2)\n",
    "        return torch.stack(spk1_rec, dim=0), torch.stack(spk2_rec, dim=0)\n",
    "\n",
    "# Instantiate model and optimizer\n",
    "net = BaselineSNN().to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "best_val_accuracy = 0.0\n",
    "epochs_no_improve = 0\n",
    "accuracies, val_accuracies, losses, total_spikes_list = [], [], [], []\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    total_spikes = 0\n",
    "    for data, targets in train_loader:\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        batch_size_actual = data.size(0)\n",
    "        if data.max() > 0:\n",
    "            data = data / data.max()  # Normalize MFCCs\n",
    "        spike_data = (torch.rand(num_steps, batch_size_actual, num_inputs, device=device) < data * 0.2).float()\n",
    "        spk1_rec, outputs = net(spike_data)\n",
    "        spk_count = outputs.sum(dim=0)\n",
    "        loss = criterion(spk_count, targets)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=3.0)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        correct = (spk_count.argmax(dim=1) == targets).sum().item()\n",
    "        accuracy = correct / batch_size_actual\n",
    "        total_spikes += (spk1_rec.sum() + outputs.sum()).item()\n",
    "    scheduler.step()\n",
    "    losses.append(loss.item())\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    # Validation\n",
    "    net.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    val_total_spikes = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            batch_size_actual = data.size(0)\n",
    "            if data.max() > 0:\n",
    "                data = data / data.max()\n",
    "            spike_data = (torch.rand(num_steps, batch_size_actual, num_inputs, device=device) < data * 0.2).float()\n",
    "            spk1_rec, outputs = net(spike_data)\n",
    "            spk_count = outputs.sum(dim=0)\n",
    "            total_correct += (spk_count.argmax(dim=1) == targets).sum().item()\n",
    "            total_samples += batch_size_actual\n",
    "            val_total_spikes += (spk1_rec.sum() + outputs.sum()).item()\n",
    "        val_accuracy = total_correct / total_samples\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        total_spikes_list.append(val_total_spikes)\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}, Total Spikes: {val_total_spikes:.0f}\")\n",
    "\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(accuracies, label=\"Train Accuracy\")\n",
    "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(losses, label=\"Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(total_spikes_list, label=\"Total Spikes\")\n",
    "plt.title(\"Total Spikes\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"baseline_snn_results.png\")\n",
    "plt.show()\n",
    "\n",
    "# Final summary\n",
    "final_val_accuracy = max(val_accuracies)\n",
    "final_total_spikes = total_spikes_list[val_accuracies.index(final_val_accuracy)]\n",
    "energy = final_total_spikes * 20 / 1e6  # µJ\n",
    "print(\"\\nBaseline SNN Final Results:\")\n",
    "print(f\"Peak Validation Accuracy: {final_val_accuracy:.2%}\")\n",
    "print(f\"Total Spikes at Peak Accuracy: {final_total_spikes:.0f}\")\n",
    "print(f\"Energy Consumption: {energy:.2f} µJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using audio backend: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aswin Kumar\\AppData\\Local\\Temp\\ipykernel_13240\\1004153853.py:13: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n",
      "C:\\Users\\Aswin Kumar\\AppData\\Local\\Temp\\ipykernel_13240\\1004153853.py:14: UserWarning: torchaudio._backend.get_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  print(f\"Using audio backend: {torchaudio.get_audio_backend()}\")\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "MFCC.__init__() got an unexpected keyword argument 'n_fft'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 73\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mfcc\u001b[38;5;241m.\u001b[39mflatten(), label\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Load datasets\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mSpeechCommandsDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m SpeechCommandsDataset(train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     75\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[1], line 42\u001b[0m, in \u001b[0;36mSpeechCommandsDataset.__init__\u001b[1;34m(self, root, train, target_words)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain \u001b[38;5;241m=\u001b[39m train\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_words \u001b[38;5;241m=\u001b[39m target_words\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m \u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMFCC\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_mfcc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m13\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m160\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mTypeError\u001b[0m: MFCC.__init__() got an unexpected keyword argument 'n_fft'"
     ]
    }
   ],
   "source": [
    "# baseline_snn_speech_commands.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import snntorch as snn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from snntorch import surrogate\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Optional: Set soundfile backend if FFmpeg fails\n",
    "try:\n",
    "    torchaudio.set_audio_backend(\"soundfile\")\n",
    "    print(f\"Using audio backend: {torchaudio.get_audio_backend()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to set soundfile backend: {e}, falling back to default\")\n",
    "    torchaudio.set_audio_backend(\"ffmpeg\")  # Default if soundfile fails\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "num_steps = 100\n",
    "num_inputs = 13 * 100\n",
    "num_hidden = 100\n",
    "num_outputs = 10\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 15\n",
    "patience = 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Check dataset\n",
    "dataset_dir = \"speech_commands_v0.02\"\n",
    "if not os.path.exists(dataset_dir):\n",
    "    print(\"Please download speech_commands_v0.02.tar.gz from http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz and extract to 'speech_commands_v0.02'\")\n",
    "    exit()\n",
    "\n",
    "# Custom Dataset for Google Speech Commands\n",
    "class SpeechCommandsDataset(Dataset):\n",
    "    def __init__(self, root=\"speech_commands_v0.02\", train=True, target_words=[\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"]):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.target_words = target_words\n",
    "        self.transform = torchaudio.transforms.MFCC(sample_rate=16000, n_mfcc=13, n_fft=400, hop_length=160, f_min=20, f_max=4000)\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        for word in os.listdir(root):\n",
    "            if word in target_words:\n",
    "                word_dir = os.path.join(root, word)\n",
    "                for file in os.listdir(word_dir):\n",
    "                    if file.endswith(\".wav\"):\n",
    "                        file_path = os.path.join(word_dir, file)\n",
    "                        label = target_words.index(word)\n",
    "                        self.data.append(file_path)\n",
    "                        self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.data[idx], self.labels[idx]\n",
    "        waveform, sample_rate = torchaudio.load(file_path)\n",
    "        if sample_rate != 16000:\n",
    "            resampler = torchaudio.transforms.Resample(sample_rate, 16000)\n",
    "            waveform = resampler(waveform)\n",
    "        mfcc = self.transform(waveform)\n",
    "        num_frames = mfcc.shape[1]\n",
    "        if num_frames < 100:\n",
    "            mfcc = torch.nn.functional.pad(mfcc, (0, 100 - num_frames))\n",
    "        else:\n",
    "            mfcc = mfcc[:, :100]\n",
    "        return mfcc.flatten(), label\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = SpeechCommandsDataset(train=True)\n",
    "test_dataset = SpeechCommandsDataset(train=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Surrogate gradient\n",
    "spike_grad = surrogate.fast_sigmoid(slope=25)\n",
    "\n",
    "# Baseline SNN\n",
    "class BaselineSNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lif1 = snn.Leaky(beta=0.9, spike_grad=spike_grad)\n",
    "        self.lif2 = snn.Leaky(beta=0.9, spike_grad=spike_grad)\n",
    "        for layer in [self.fc1, self.fc2]:\n",
    "            nn.init.xavier_uniform_(layer.weight, gain=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(1)\n",
    "        mem1, mem2 = self.lif1.init_leaky(), self.lif2.init_leaky()\n",
    "        spk1_rec, spk2_rec = [], []\n",
    "        for step in range(num_steps):\n",
    "            cur1 = self.fc1(x[step])\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk1_rec.append(spk1)\n",
    "            spk2_rec.append(spk2)\n",
    "        return torch.stack(spk1_rec, dim=0), torch.stack(spk2_rec, dim=0)\n",
    "\n",
    "# Instantiate model and optimizer\n",
    "net = BaselineSNN().to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "best_val_accuracy = 0.0\n",
    "epochs_no_improve = 0\n",
    "accuracies, val_accuracies, losses, total_spikes_list = [], [], [], []\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    total_spikes = 0\n",
    "    for data, targets in train_loader:\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        batch_size_actual = data.size(0)\n",
    "        if data.max() > 0:\n",
    "            data = data / data.max()\n",
    "        spike_data = (torch.rand(num_steps, batch_size_actual, num_inputs, device=device) < data * 0.2).float()\n",
    "        spk1_rec, outputs = net(spike_data)\n",
    "        spk_count = outputs.sum(dim=0)\n",
    "        loss = criterion(spk_count, targets)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=3.0)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        correct = (spk_count.argmax(dim=1) == targets).sum().item()\n",
    "        accuracy = correct / batch_size_actual\n",
    "        total_spikes += (spk1_rec.sum() + outputs.sum()).item()\n",
    "    scheduler.step()\n",
    "    losses.append(loss.item())\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    # Validation\n",
    "    net.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    val_total_spikes = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            batch_size_actual = data.size(0)\n",
    "            if data.max() > 0:\n",
    "                data = data / data.max()\n",
    "            spike_data = (torch.rand(num_steps, batch_size_actual, num_inputs, device=device) < data * 0.2).float()\n",
    "            spk1_rec, outputs = net(spike_data)\n",
    "            spk_count = outputs.sum(dim=0)\n",
    "            total_correct += (spk_count.argmax(dim=1) == targets).sum().item()\n",
    "            total_samples += batch_size_actual\n",
    "            val_total_spikes += (spk1_rec.sum() + outputs.sum()).item()\n",
    "        val_accuracy = total_correct / total_samples\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        total_spikes_list.append(val_total_spikes)\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}, Total Spikes: {val_total_spikes:.0f}\")\n",
    "\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(accuracies, label=\"Train Accuracy\")\n",
    "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(losses, label=\"Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(total_spikes_list, label=\"Total Spikes\")\n",
    "plt.title(\"Total Spikes\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"baseline_snn_results.png\")\n",
    "plt.show()\n",
    "\n",
    "# Final summary\n",
    "final_val_accuracy = max(val_accuracies)\n",
    "final_total_spikes = total_spikes_list[val_accuracies.index(final_val_accuracy)]\n",
    "energy = final_total_spikes * 20 / 1e6  # µJ\n",
    "print(\"\\nBaseline SNN Final Results:\")\n",
    "print(f\"Peak Validation Accuracy: {final_val_accuracy:.2%}\")\n",
    "print(f\"Total Spikes at Peak Accuracy: {final_total_spikes:.0f}\")\n",
    "print(f\"Energy Consumption: {energy:.2f} µJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [2444] at entry 0 and [2119] at entry 8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 119\u001b[0m\n\u001b[0;32m    117\u001b[0m net\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    118\u001b[0m total_spikes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 119\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size_actual\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:144\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtransposed\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:144\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:121\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:174\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    172\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    173\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [2444] at entry 0 and [2119] at entry 8"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import snntorch as snn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from snntorch import surrogate\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "num_steps = 100  # 1 second at 10 ms frames\n",
    "num_inputs = 13 * 100  # 13 MFCCs, 100 frames\n",
    "num_hidden = 100\n",
    "num_outputs = 10  # 10 command words\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 15\n",
    "patience = 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Check dataset\n",
    "dataset_dir = \"speech_commands_v0.02\"\n",
    "if not os.path.exists(dataset_dir):\n",
    "    print(\"Please download speech_commands_v0.02.tar.gz from http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz and extract to 'speech_commands_v0.02'\")\n",
    "    exit()\n",
    "\n",
    "# Custom Dataset for Google Speech Commands\n",
    "class SpeechCommandsDataset(Dataset):\n",
    "    def __init__(self, root=\"speech_commands_v0.02\", train=True, target_words=[\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"]):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.target_words = target_words\n",
    "        self.transform = torchaudio.transforms.MFCC(\n",
    "            sample_rate=16000,\n",
    "            n_mfcc=13,\n",
    "            melkwargs={\n",
    "                'n_fft': 400,\n",
    "                'hop_length': 160,\n",
    "                'f_min': 20,\n",
    "                'f_max': 4000,\n",
    "                'n_mels': 40\n",
    "            }\n",
    "        )\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        for word in os.listdir(root):\n",
    "            if word in target_words:\n",
    "                word_dir = os.path.join(root, word)\n",
    "                for file in os.listdir(word_dir):\n",
    "                    if file.endswith(\".wav\"):\n",
    "                        file_path = os.path.join(word_dir, file)\n",
    "                        label = target_words.index(word)\n",
    "                        self.data.append(file_path)\n",
    "                        self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.data[idx], self.labels[idx]\n",
    "        waveform, sample_rate = torchaudio.load(file_path)\n",
    "        if sample_rate != 16000:\n",
    "            resampler = torchaudio.transforms.Resample(sample_rate, 16000)\n",
    "            waveform = resampler(waveform)\n",
    "        mfcc = self.transform(waveform)\n",
    "        num_frames = mfcc.shape[1]\n",
    "        if num_frames < 100:\n",
    "            mfcc = torch.nn.functional.pad(mfcc, (0, 100 - num_frames))\n",
    "        else:\n",
    "            mfcc = mfcc[:, :100]\n",
    "        return mfcc.flatten(), label\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = SpeechCommandsDataset(train=True)\n",
    "test_dataset = SpeechCommandsDataset(train=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Surrogate gradient\n",
    "spike_grad = surrogate.fast_sigmoid(slope=25)\n",
    "\n",
    "# Baseline SNN\n",
    "class BaselineSNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lif1 = snn.Leaky(beta=0.9, spike_grad=spike_grad)\n",
    "        self.lif2 = snn.Leaky(beta=0.9, spike_grad=spike_grad)\n",
    "        for layer in [self.fc1, self.fc2]:\n",
    "            nn.init.xavier_uniform_(layer.weight, gain=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(1)\n",
    "        mem1, mem2 = self.lif1.init_leaky(), self.lif2.init_leaky()\n",
    "        spk1_rec, spk2_rec = [], []\n",
    "        for step in range(num_steps):\n",
    "            cur1 = self.fc1(x[step])\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk1_rec.append(spk1)\n",
    "            spk2_rec.append(spk2)\n",
    "        return torch.stack(spk1_rec, dim=0), torch.stack(spk2_rec, dim=0)\n",
    "\n",
    "# Instantiate model and optimizer\n",
    "net = BaselineSNN().to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "best_val_accuracy = 0.0\n",
    "epochs_no_improve = 0\n",
    "accuracies, val_accuracies, losses, total_spikes_list = [], [], [], []\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    total_spikes = 0\n",
    "    for data, targets in train_loader:\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        batch_size_actual = data.size(0)\n",
    "        if data.max() > 0:\n",
    "            data = data / data.max()\n",
    "        spike_data = (torch.rand(num_steps, batch_size_actual, num_inputs, device=device) < data * 0.2).float()\n",
    "        spk1_rec, outputs = net(spike_data)\n",
    "        spk_count = outputs.sum(dim=0)\n",
    "        loss = criterion(spk_count, targets)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=3.0)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        correct = (spk_count.argmax(dim=1) == targets).sum().item()\n",
    "        accuracy = correct / batch_size_actual\n",
    "        total_spikes += (spk1_rec.sum() + outputs.sum()).item()\n",
    "    scheduler.step()\n",
    "    losses.append(loss.item())\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    # Validation\n",
    "    net.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    val_total_spikes = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            batch_size_actual = data.size(0)\n",
    "            if data.max() > 0:\n",
    "                data = data / data.max()\n",
    "            spike_data = (torch.rand(num_steps, batch_size_actual, num_inputs, device=device) < data * 0.2).float()\n",
    "            spk1_rec, outputs = net(spike_data)\n",
    "            spk_count = outputs.sum(dim=0)\n",
    "            total_correct += (spk_count.argmax(dim=1) == targets).sum().item()\n",
    "            total_samples += batch_size_actual\n",
    "            val_total_spikes += (spk1_rec.sum() + outputs.sum()).item()\n",
    "        val_accuracy = total_correct / total_samples\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        total_spikes_list.append(val_total_spikes)\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}, Total Spikes: {val_total_spikes:.0f}\")\n",
    "\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(accuracies, label=\"Train Accuracy\")\n",
    "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(losses, label=\"Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(total_spikes_list, label=\"Total Spikes\")\n",
    "plt.title(\"Total Spikes\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"baseline_snn_results.png\")\n",
    "plt.show()\n",
    "\n",
    "# Final summary\n",
    "final_val_accuracy = max(val_accuracies)\n",
    "final_total_spikes = total_spikes_list[val_accuracies.index(final_val_accuracy)]\n",
    "energy = final_total_spikes * 20 / 1e6  # µJ\n",
    "print(\"\\nBaseline SNN Final Results:\")\n",
    "print(f\"Peak Validation Accuracy: {final_val_accuracy:.2%}\")\n",
    "print(f\"Total Spikes at Peak Accuracy: {final_total_spikes:.0f}\")\n",
    "print(f\"Energy Consumption: {energy:.2f} µJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [2171] at entry 0 and [2444] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 119\u001b[0m\n\u001b[0;32m    117\u001b[0m net\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    118\u001b[0m total_spikes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 119\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size_actual\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:144\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtransposed\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:144\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:121\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:174\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    172\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    173\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [2171] at entry 0 and [2444] at entry 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import snntorch as snn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from snntorch import surrogate\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "num_steps = 100  # 1 second at 10 ms frames\n",
    "num_inputs = 13 * 100  # 13 MFCCs, 100 frames\n",
    "num_hidden = 100\n",
    "num_outputs = 10  # 10 command words\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 15\n",
    "patience = 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Check dataset\n",
    "dataset_dir = \"speech_commands_v0.02\"\n",
    "if not os.path.exists(dataset_dir):\n",
    "    print(\"Please download speech_commands_v0.02.tar.gz from http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz and extract to 'speech_commands_v0.02'\")\n",
    "    exit()\n",
    "\n",
    "# Custom Dataset for Google Speech Commands\n",
    "class SpeechCommandsDataset(Dataset):\n",
    "    def __init__(self, root=\"speech_commands_v0.02\", train=True, target_words=[\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"]):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.target_words = target_words\n",
    "        self.transform = torchaudio.transforms.MFCC(\n",
    "            sample_rate=16000,\n",
    "            n_mfcc=13,\n",
    "            melkwargs={\n",
    "                'n_fft': 400,\n",
    "                'hop_length': 160,\n",
    "                'f_min': 20,\n",
    "                'f_max': 4000,\n",
    "                'n_mels': 40\n",
    "            }\n",
    "        )\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        for word in os.listdir(root):\n",
    "            if word in target_words:\n",
    "                word_dir = os.path.join(root, word)\n",
    "                for file in os.listdir(word_dir):\n",
    "                    if file.endswith(\".wav\"):\n",
    "                        file_path = os.path.join(word_dir, file)\n",
    "                        label = target_words.index(word)\n",
    "                        self.data.append(file_path)\n",
    "                        self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.data[idx], self.labels[idx]\n",
    "        waveform, sample_rate = torchaudio.load(file_path)\n",
    "        if sample_rate != 16000:\n",
    "            resampler = torchaudio.transforms.Resample(sample_rate, 16000)\n",
    "            waveform = resampler(waveform)\n",
    "        mfcc = self.transform(waveform)\n",
    "        num_frames = mfcc.shape[1]\n",
    "        if num_frames < 100:\n",
    "            mfcc = torch.nn.functional.pad(mfcc, (0, 100 - num_frames))\n",
    "        else:\n",
    "            mfcc = mfcc[:, :100]\n",
    "        return mfcc.flatten(), label\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = SpeechCommandsDataset(train=True)\n",
    "test_dataset = SpeechCommandsDataset(train=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Surrogate gradient\n",
    "spike_grad = surrogate.fast_sigmoid(slope=25)\n",
    "\n",
    "# Baseline SNN\n",
    "class BaselineSNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lif1 = snn.Leaky(beta=0.9, spike_grad=spike_grad)\n",
    "        self.lif2 = snn.Leaky(beta=0.9, spike_grad=spike_grad)\n",
    "        for layer in [self.fc1, self.fc2]:\n",
    "            nn.init.xavier_uniform_(layer.weight, gain=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(1)\n",
    "        mem1, mem2 = self.lif1.init_leaky(), self.lif2.init_leaky()\n",
    "        spk1_rec, spk2_rec = [], []\n",
    "        for step in range(num_steps):\n",
    "            cur1 = self.fc1(x[step])\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk1_rec.append(spk1)\n",
    "            spk2_rec.append(spk2)\n",
    "        return torch.stack(spk1_rec, dim=0), torch.stack(spk2_rec, dim=0)\n",
    "\n",
    "# Instantiate model and optimizer\n",
    "net = BaselineSNN().to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "best_val_accuracy = 0.0\n",
    "epochs_no_improve = 0\n",
    "accuracies, val_accuracies, losses, total_spikes_list = [], [], [], []\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    total_spikes = 0\n",
    "    for data, targets in train_loader:\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        batch_size_actual = data.size(0)\n",
    "        if data.max() > 0:\n",
    "            data = data / data.max()\n",
    "        spike_data = (torch.rand(num_steps, batch_size_actual, num_inputs, device=device) < data * 0.2).float()\n",
    "        spk1_rec, outputs = net(spike_data)\n",
    "        spk_count = outputs.sum(dim=0)\n",
    "        loss = criterion(spk_count, targets)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=3.0)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        correct = (spk_count.argmax(dim=1) == targets).sum().item()\n",
    "        accuracy = correct / batch_size_actual\n",
    "        total_spikes += (spk1_rec.sum() + outputs.sum()).item()\n",
    "    scheduler.step()\n",
    "    losses.append(loss.item())\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    # Validation\n",
    "    net.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    val_total_spikes = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            batch_size_actual = data.size(0)\n",
    "            if data.max() > 0:\n",
    "                data = data / data.max()\n",
    "            spike_data = (torch.rand(num_steps, batch_size_actual, num_inputs, device=device) < data * 0.2).float()\n",
    "            spk1_rec, outputs = net(spike_data)\n",
    "            spk_count = outputs.sum(dim=0)\n",
    "            total_correct += (spk_count.argmax(dim=1) == targets).sum().item()\n",
    "            total_samples += batch_size_actual\n",
    "            val_total_spikes += (spk1_rec.sum() + outputs.sum()).item()\n",
    "        val_accuracy = total_correct / total_samples\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        total_spikes_list.append(val_total_spikes)\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}, Total Spikes: {val_total_spikes:.0f}\")\n",
    "\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(accuracies, label=\"Train Accuracy\")\n",
    "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(losses, label=\"Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(total_spikes_list, label=\"Total Spikes\")\n",
    "plt.title(\"Total Spikes\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"baseline_snn_results.png\")\n",
    "plt.show()\n",
    "\n",
    "# Final summary\n",
    "final_val_accuracy = max(val_accuracies)\n",
    "final_total_spikes = total_spikes_list[val_accuracies.index(final_val_accuracy)]\n",
    "energy = final_total_spikes * 20 / 1e6  # µJ\n",
    "print(\"\\nBaseline SNN Final Results:\")\n",
    "print(f\"Peak Validation Accuracy: {final_val_accuracy:.2%}\")\n",
    "print(f\"Total Spikes at Peak Accuracy: {final_total_spikes:.0f}\")\n",
    "print(f\"Energy Consumption: {energy:.2f} µJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.1823, Accuracy: 0.5556, Validation Accuracy: 0.4109, Total Spikes: 4550032\n",
      "Epoch 2, Loss: 0.9965, Accuracy: 0.6667, Validation Accuracy: 0.4785, Total Spikes: 6609538\n",
      "Epoch 3, Loss: 1.0580, Accuracy: 0.5556, Validation Accuracy: 0.5248, Total Spikes: 7864943\n",
      "Epoch 4, Loss: 0.9512, Accuracy: 0.6111, Validation Accuracy: 0.5464, Total Spikes: 8573723\n",
      "Epoch 5, Loss: 0.7383, Accuracy: 0.6667, Validation Accuracy: 0.5538, Total Spikes: 9200263\n",
      "Epoch 6, Loss: 0.8862, Accuracy: 0.6667, Validation Accuracy: 0.5636, Total Spikes: 9662320\n",
      "Epoch 7, Loss: 0.9828, Accuracy: 0.5556, Validation Accuracy: 0.5652, Total Spikes: 9776776\n",
      "Epoch 8, Loss: 1.0497, Accuracy: 0.7222, Validation Accuracy: 0.5650, Total Spikes: 9874394\n",
      "Epoch 9, Loss: 0.9734, Accuracy: 0.6111, Validation Accuracy: 0.5656, Total Spikes: 9923252\n",
      "Epoch 10, Loss: 1.1593, Accuracy: 0.6111, Validation Accuracy: 0.5695, Total Spikes: 9964282\n",
      "Epoch 11, Loss: 0.6891, Accuracy: 0.6667, Validation Accuracy: 0.5699, Total Spikes: 9971897\n",
      "Epoch 12, Loss: 1.1605, Accuracy: 0.6111, Validation Accuracy: 0.5682, Total Spikes: 9986701\n",
      "Epoch 13, Loss: 1.4423, Accuracy: 0.5556, Validation Accuracy: 0.5671, Total Spikes: 9990291\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 153\u001b[0m\n\u001b[0;32m    151\u001b[0m     data \u001b[38;5;241m=\u001b[39m data \u001b[38;5;241m/\u001b[39m data\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m    152\u001b[0m spike_data \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mrand(num_steps, batch_size_actual, num_inputs, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;241m<\u001b[39m data \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.2\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m--> 153\u001b[0m spk1_rec, outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspike_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m spk_count \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    155\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(spk_count, targets)\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 124\u001b[0m, in \u001b[0;36mBaselineSNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    122\u001b[0m spk1, mem1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlif1(cur1, mem1)\n\u001b[0;32m    123\u001b[0m cur2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(spk1)\n\u001b[1;32m--> 124\u001b[0m spk2, mem2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlif2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmem2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m spk1_rec\u001b[38;5;241m.\u001b[39mappend(spk1)\n\u001b[0;32m    126\u001b[0m spk2_rec\u001b[38;5;241m.\u001b[39mappend(spk2)\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\snntorch\\_neurons\\leaky.py:220\u001b[0m, in \u001b[0;36mLeaky.forward\u001b[1;34m(self, input_, mem)\u001b[0m\n\u001b[0;32m    216\u001b[0m     spk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfire_inhibition(\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmem\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmem\n\u001b[0;32m    218\u001b[0m     )  \u001b[38;5;66;03m# batch_size\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 220\u001b[0m     spk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_delay:\n\u001b[0;32m    223\u001b[0m     do_reset \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    224\u001b[0m         spk \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraded_spikes_factor \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset\n\u001b[0;32m    225\u001b[0m     )  \u001b[38;5;66;03m# avoid double reset\u001b[39;00m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\snntorch\\_neurons\\neurons.py:81\u001b[0m, in \u001b[0;36mSpikingNeuron.fire\u001b[1;34m(self, mem)\u001b[0m\n\u001b[0;32m     78\u001b[0m     mem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_quant(mem)\n\u001b[0;32m     80\u001b[0m mem_shift \u001b[38;5;241m=\u001b[39m mem \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold\n\u001b[1;32m---> 81\u001b[0m spk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspike_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmem_shift\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m spk \u001b[38;5;241m=\u001b[39m spk \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraded_spikes_factor\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m spk\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\snntorch\\surrogate.py:151\u001b[0m, in \u001b[0;36mfast_sigmoid.<locals>.inner\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner\u001b[39m(x):\n\u001b[1;32m--> 151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFastSigmoid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslope\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\autograd\\function.py:553\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[0;32m    552\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[1;32m--> 553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    557\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    559\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    560\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    561\u001b[0m     )\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\snntorch\\surrogate.py:135\u001b[0m, in \u001b[0;36mFastSigmoid.forward\u001b[1;34m(ctx, input_, slope)\u001b[0m\n\u001b[0;32m    133\u001b[0m ctx\u001b[38;5;241m.\u001b[39msave_for_backward(input_)\n\u001b[0;32m    134\u001b[0m ctx\u001b[38;5;241m.\u001b[39mslope \u001b[38;5;241m=\u001b[39m slope\n\u001b[1;32m--> 135\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43minput_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import snntorch as snn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from snntorch import surrogate\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "num_steps = 100  # 1 second at 10 ms frames\n",
    "num_inputs = 1300  # 13 MFCCs × 100 frames\n",
    "num_hidden = 100\n",
    "num_outputs = 10  # 10 command words\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 15\n",
    "patience = 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Check dataset\n",
    "dataset_dir = \"speech_commands_v0.02\"\n",
    "if not os.path.exists(dataset_dir):\n",
    "    print(\"Please download speech_commands_v0.02.tar.gz from http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz and extract to 'speech_commands_v0.02'\")\n",
    "    exit()\n",
    "\n",
    "# Custom Dataset for Google Speech Commands\n",
    "class SpeechCommandsDataset(Dataset):\n",
    "    def __init__(self, root=\"speech_commands_v0.02\", train=True, target_words=[\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"]):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.target_words = target_words\n",
    "        self.transform = torchaudio.transforms.MFCC(\n",
    "            sample_rate=16000,\n",
    "            n_mfcc=13,\n",
    "            melkwargs={\n",
    "                'n_fft': 400,\n",
    "                'hop_length': 160,\n",
    "                'f_min': 20,\n",
    "                'f_max': 4000,\n",
    "                'n_mels': 40\n",
    "            }\n",
    "        )\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        for word in os.listdir(root):\n",
    "            if word in target_words:\n",
    "                word_dir = os.path.join(root, word)\n",
    "                for file in os.listdir(word_dir):\n",
    "                    if file.endswith(\".wav\"):\n",
    "                        file_path = os.path.join(word_dir, file)\n",
    "                        label = target_words.index(word)\n",
    "                        self.data.append(file_path)\n",
    "                        self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.data[idx], self.labels[idx]\n",
    "        try:\n",
    "            waveform, sample_rate = torchaudio.load(file_path)\n",
    "            if waveform.numel() == 0:\n",
    "                raise ValueError(\"Empty waveform\")\n",
    "            if sample_rate != 16000:\n",
    "                resampler = torchaudio.transforms.Resample(sample_rate, 16000)\n",
    "                waveform = resampler(waveform)\n",
    "            mfcc = self.transform(waveform)\n",
    "            if mfcc.dim() == 3 and mfcc.shape[0] == 1:\n",
    "                mfcc = mfcc.squeeze(0)  # Shape: [13, num_frames]\n",
    "            num_frames = mfcc.shape[1]\n",
    "            if num_frames < 100:\n",
    "                pad_width = 100 - num_frames\n",
    "                mfcc = torch.nn.functional.pad(mfcc, (0, pad_width))\n",
    "            elif num_frames > 100:\n",
    "                mfcc = mfcc[:, :100]\n",
    "            flattened = mfcc.flatten()  # Shape: [1300]\n",
    "            return flattened, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "            return torch.zeros(1300), -1  # Dummy tensor and label\n",
    "\n",
    "# Custom collate function\n",
    "def collate_fn(batch):\n",
    "    data = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "    valid_indices = [i for i, target in enumerate(targets) if target != -1]\n",
    "    if not valid_indices:\n",
    "        return torch.zeros(1, 1300), torch.zeros(1, dtype=torch.long)\n",
    "    data = [data[i] for i in valid_indices]\n",
    "    targets = [targets[i] for i in valid_indices]\n",
    "    data = torch.stack(data)\n",
    "    targets = torch.tensor(targets)\n",
    "    return data, targets\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = SpeechCommandsDataset(train=True)\n",
    "test_dataset = SpeechCommandsDataset(train=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# Surrogate gradient\n",
    "spike_grad = surrogate.fast_sigmoid(slope=25)\n",
    "\n",
    "# Baseline SNN\n",
    "class BaselineSNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lif1 = snn.Leaky(beta=0.9, spike_grad=spike_grad)\n",
    "        self.lif2 = snn.Leaky(beta=0.9, spike_grad=spike_grad)\n",
    "        for layer in [self.fc1, self.fc2]:\n",
    "            nn.init.xavier_uniform_(layer.weight, gain=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(1)\n",
    "        mem1, mem2 = self.lif1.init_leaky(), self.lif2.init_leaky()\n",
    "        spk1_rec, spk2_rec = [], []\n",
    "        for step in range(num_steps):\n",
    "            cur1 = self.fc1(x[step])\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk1_rec.append(spk1)\n",
    "            spk2_rec.append(spk2)\n",
    "        return torch.stack(spk1_rec, dim=0), torch.stack(spk2_rec, dim=0)\n",
    "\n",
    "# Instantiate model and optimizer\n",
    "net = BaselineSNN().to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "best_val_accuracy = 0.0\n",
    "epochs_no_improve = 0\n",
    "accuracies, val_accuracies, losses, total_spikes_list = [], [], [], []\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    total_spikes = 0\n",
    "    for data, targets in train_loader:\n",
    "        valid_indices = targets != -1\n",
    "        if not valid_indices.any():\n",
    "            continue\n",
    "        data = data[valid_indices]\n",
    "        targets = targets[valid_indices]\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        batch_size_actual = data.size(0)\n",
    "        if data.max() > 0:\n",
    "            data = data / data.max()\n",
    "        spike_data = (torch.rand(num_steps, batch_size_actual, num_inputs, device=device) < data * 0.2).float()\n",
    "        spk1_rec, outputs = net(spike_data)\n",
    "        spk_count = outputs.sum(dim=0)\n",
    "        loss = criterion(spk_count, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=3.0)\n",
    "        optimizer.step()\n",
    "        correct = (spk_count.argmax(dim=1) == targets).sum().item()\n",
    "        accuracy = correct / batch_size_actual\n",
    "        total_spikes += (spk1_rec.sum() + outputs.sum()).item()\n",
    "    scheduler.step()\n",
    "    losses.append(loss.item())\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    # Validation\n",
    "    net.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    val_total_spikes = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            valid_indices = targets != -1\n",
    "            if not valid_indices.any():\n",
    "                continue\n",
    "            data = data[valid_indices]\n",
    "            targets = targets[valid_indices]\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            batch_size_actual = data.size(0)\n",
    "            if data.max() > 0:\n",
    "                data = data / data.max()\n",
    "            spike_data = (torch.rand(num_steps, batch_size_actual, num_inputs, device=device) < data * 0.2).float()\n",
    "            spk1_rec, outputs = net(spike_data)\n",
    "            spk_count = outputs.sum(dim=0)\n",
    "            total_correct += (spk_count.argmax(dim=1) == targets).sum().item()\n",
    "            total_samples += batch_size_actual\n",
    "            val_total_spikes += (spk1_rec.sum() + outputs.sum()).item()\n",
    "        val_accuracy = total_correct / total_samples if total_samples > 0 else 0.0\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        total_spikes_list.append(val_total_spikes)\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}, Total Spikes: {val_total_spikes:.0f}\")\n",
    "\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(accuracies, label=\"Train Accuracy\")\n",
    "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(losses, label=\"Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(total_spikes_list, label=\"Total Spikes\")\n",
    "plt.title(\"Total Spikes\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"baseline_snn_results.png\")\n",
    "plt.show()\n",
    "\n",
    "# Final summary\n",
    "final_val_accuracy = max(val_accuracies) if val_accuracies else 0.0\n",
    "final_total_spikes = total_spikes_list[val_accuracies.index(final_val_accuracy)] if val_accuracies else 0\n",
    "energy = final_total_spikes * 20 / 1e6  # µJ\n",
    "print(\"\\nBaseline SNN Final Results:\")\n",
    "print(f\"Peak Validation Accuracy: {final_val_accuracy:.2%}\")\n",
    "print(f\"Total Spikes at Peak Accuracy: {final_total_spikes:.0f}\")\n",
    "print(f\"Energy Consumption: {energy:.2f} µJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mem2_rec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 165\u001b[0m\n\u001b[0;32m    161\u001b[0m spike_data \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mrand(num_steps, batch_size_actual, num_inputs, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;241m<\u001b[39m\n\u001b[0;32m    162\u001b[0m               data\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# Increased scaling factor to 0.5\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m--> 165\u001b[0m outputs, _ \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspike_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m spk_count \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Sum over time steps: [batch_size, num_classes]\u001b[39;00m\n\u001b[0;32m    167\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(spk_count, targets)\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 129\u001b[0m, in \u001b[0;36mSNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    126\u001b[0m     spk1_rec\u001b[38;5;241m.\u001b[39mappend(spk1)\n\u001b[0;32m    127\u001b[0m     spk2_rec\u001b[38;5;241m.\u001b[39mappend(spk2)\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(spk2_rec, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), torch\u001b[38;5;241m.\u001b[39mstack(\u001b[43mmem2_rec\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mem2_rec' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import snntorch as snn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from snntorch import surrogate\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "num_steps = 100  # Number of time steps (frames)\n",
    "num_inputs = 13  # 13 MFCC coefficients per frame\n",
    "num_hidden = 256  # Increased for better capacity\n",
    "num_outputs = 10  # 10 command words\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 20\n",
    "patience = 5\n",
    "beta = 0.95  # Adjusted for longer memory\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Check dataset\n",
    "dataset_dir = \"speech_commands_v0.02\"\n",
    "if not os.path.exists(dataset_dir):\n",
    "    print(\"Please download speech_commands_v0.02.tar.gz from http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz and extract to 'speech_commands_v0.02'\")\n",
    "    exit()\n",
    "\n",
    "# Custom Dataset for Google Speech Commands\n",
    "class SpeechCommandsDataset(Dataset):\n",
    "    def __init__(self, root=\"speech_commands_v0.02\", train=True, target_words=[\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"]):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.target_words = target_words\n",
    "        self.transform = torchaudio.transforms.MFCC(\n",
    "            sample_rate=16000,\n",
    "            n_mfcc=13,\n",
    "            melkwargs={\n",
    "                'n_fft': 400,\n",
    "                'hop_length': 160,\n",
    "                'f_min': 20,\n",
    "                'f_max': 4000,\n",
    "                'n_mels': 40\n",
    "            }\n",
    "        )\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        for word in os.listdir(root):\n",
    "            if word in target_words:\n",
    "                word_dir = os.path.join(root, word)\n",
    "                for file in os.listdir(word_dir):\n",
    "                    if file.endswith(\".wav\"):\n",
    "                        file_path = os.path.join(word_dir, file)\n",
    "                        label = target_words.index(word)\n",
    "                        self.data.append(file_path)\n",
    "                        self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.data[idx], self.labels[idx]\n",
    "        try:\n",
    "            waveform, sample_rate = torchaudio.load(file_path)\n",
    "            if waveform.numel() == 0:\n",
    "                raise ValueError(\"Empty waveform\")\n",
    "            if sample_rate != 16000:\n",
    "                resampler = torchaudio.transforms.Resample(sample_rate, 16000)\n",
    "                waveform = resampler(waveform)\n",
    "            mfcc = self.transform(waveform)\n",
    "            if mfcc.dim() == 3 and mfcc.shape[0] == 1:\n",
    "                mfcc = mfcc.squeeze(0)  # Shape: [13, num_frames]\n",
    "            num_frames = mfcc.shape[1]\n",
    "            if num_frames < 100:\n",
    "                pad_width = 100 - num_frames\n",
    "                mfcc = torch.nn.functional.pad(mfcc, (0, pad_width))\n",
    "            elif num_frames > 100:\n",
    "                mfcc = mfcc[:, :100]\n",
    "            mfcc = mfcc.transpose(0, 1)  # Shape: [100, 13]\n",
    "            return mfcc, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "            return torch.zeros(100, 13), -1  # Dummy tensor and label\n",
    "\n",
    "# Custom collate function\n",
    "def collate_fn(batch):\n",
    "    data = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "    valid_indices = [i for i, target in enumerate(targets) if target != -1]\n",
    "    if not valid_indices:\n",
    "        return torch.zeros(1, 100, 13), torch.zeros(1, dtype=torch.long)\n",
    "    data = [data[i] for i in valid_indices]\n",
    "    targets = [targets[i] for i in valid_indices]\n",
    "    data = torch.stack(data)\n",
    "    targets = torch.tensor(targets)\n",
    "    return data, targets\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = SpeechCommandsDataset(train=True)\n",
    "test_dataset = SpeechCommandsDataset(train=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# SNN Model\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self, num_inputs=13, num_hidden=256, num_classes=10, beta=0.95):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.lif1 = snn.Leaky(beta=beta, spike_grad=surrogate.fast_sigmoid(slope=25))\n",
    "        self.fc2 = nn.Linear(num_hidden, num_classes)\n",
    "        self.lif2 = snn.Leaky(beta=beta, spike_grad=surrogate.fast_sigmoid(slope=25))\n",
    "        for layer in [self.fc1, self.fc2]:\n",
    "            nn.init.xavier_uniform_(layer.weight, gain=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(1)\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        spk1_rec = []\n",
    "        spk2_rec = []\n",
    "\n",
    "        for step in range(x.size(0)):  # x: [num_steps, batch_size, 13]\n",
    "            cur1 = self.fc1(x[step])  # x[step]: [batch_size, 13]\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk1_rec.append(spk1)\n",
    "            spk2_rec.append(spk2)\n",
    "\n",
    "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)  # [num_steps, batch_size, num_classes]\n",
    "\n",
    "# Instantiate model and optimizer\n",
    "net = SNN().to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "best_val_accuracy = 0.0\n",
    "epochs_no_improve = 0\n",
    "accuracies, val_accuracies, losses, total_spikes_list = [], [], [], []\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    total_spikes = 0\n",
    "    for data, targets in train_loader:\n",
    "        valid_indices = targets != -1\n",
    "        if not valid_indices.any():\n",
    "            continue\n",
    "        data = data[valid_indices]\n",
    "        targets = targets[valid_indices]\n",
    "        data, targets = data.to(device), targets.to(device)  # data: [batch_size, 100, 13]\n",
    "        batch_size_actual = data.size(0)\n",
    "\n",
    "        # Normalize MFCCs per sample to [0, 1]\n",
    "        data_flat = data.view(batch_size_actual, -1)  # [batch_size, 1300]\n",
    "        data_min = data_flat.min(dim=1, keepdim=True)[0].unsqueeze(2)  # [batch_size, 1, 1]\n",
    "        data_max = data_flat.max(dim=1, keepdim=True)[0].unsqueeze(2)  # [batch_size, 1, 1]\n",
    "        data = (data - data_min) / (data_max - data_min + 1e-8)\n",
    "        data = torch.clamp(data, 0, 1)  # [batch_size, 100, 13]\n",
    "\n",
    "        # Generate spikes: [num_steps, batch_size, 13]\n",
    "        spike_data = (torch.rand(num_steps, batch_size_actual, num_inputs, device=device) <\n",
    "                      data.permute(1, 0, 2) * 0.5).float()  # Increased scaling factor to 0.5\n",
    "\n",
    "        # Forward pass\n",
    "        outputs, _ = net(spike_data)\n",
    "        spk_count = outputs.sum(dim=0)  # Sum over time steps: [batch_size, num_classes]\n",
    "        loss = criterion(spk_count, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=3.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        correct = (spk_count.argmax(dim=1) == targets).sum().item()\n",
    "        accuracy = correct / batch_size_actual\n",
    "        total_spikes += outputs.sum().item()\n",
    "\n",
    "    scheduler.step()\n",
    "    losses.append(loss.item())\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    # Validation\n",
    "    net.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    val_total_spikes = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            valid_indices = targets != -1\n",
    "            if not valid_indices.any():\n",
    "                continue\n",
    "            data = data[valid_indices]\n",
    "            targets = targets[valid_indices]\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            batch_size_actual = data.size(0)\n",
    "\n",
    "            # Normalize and generate spikes (same as training)\n",
    "            data_flat = data.view(batch_size_actual, -1)\n",
    "            data_min = data_flat.min(dim=1, keepdim=True)[0].unsqueeze(2)\n",
    "            data_max = data_flat.max(dim=1, keepdim=True)[0].unsqueeze(2)\n",
    "            data = (data - data_min) / (data_max - data_min + 1e-8)\n",
    "            data = torch.clamp(data, 0, 1)\n",
    "            spike_data = (torch.rand(num_steps, batch_size_actual, num_inputs, device=device) <\n",
    "                          data.permute(1, 0, 2) * 0.5).float()\n",
    "            outputs, _ = net(spike_data)\n",
    "            spk_count = outputs.sum(dim=0)\n",
    "            total_correct += (spk_count.argmax(dim=1) == targets).sum().item()\n",
    "            total_samples += batch_size_actual\n",
    "            val_total_spikes += outputs.sum().item()\n",
    "\n",
    "        val_accuracy = total_correct / total_samples if total_samples > 0 else 0.0\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        total_spikes_list.append(val_total_spikes)\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}, Total Spikes: {val_total_spikes:.0f}\")\n",
    "\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(accuracies, label=\"Train Accuracy\")\n",
    "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(losses, label=\"Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(total_spikes_list, label=\"Total Spikes\")\n",
    "plt.title(\"Total Spikes\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"baseline_snn_results.png\")\n",
    "plt.show()\n",
    "\n",
    "# Final summary\n",
    "final_val_accuracy = max(val_accuracies) if val_accuracies else 0.0\n",
    "final_total_spikes = total_spikes_list[val_accuracies.index(final_val_accuracy)] if val_accuracies else 0\n",
    "energy = final_total_spikes * 20 / 1e6  # µJ\n",
    "print(\"\\nBaseline SNN Final Results:\")\n",
    "print(f\"Peak Validation Accuracy: {final_val_accuracy:.2%}\")\n",
    "print(f\"Total Spikes at Peak Accuracy: {final_total_spikes:.0f}\")\n",
    "print(f\"Energy Consumption: {energy:.2f} µJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.3202, Accuracy: 0.0556, Validation Accuracy: 0.1144, Total Spikes: 3496\n",
      "Epoch 2, Loss: 2.3075, Accuracy: 0.1667, Validation Accuracy: 0.1409, Total Spikes: 48824\n",
      "Epoch 3, Loss: 2.3297, Accuracy: 0.1667, Validation Accuracy: 0.1548, Total Spikes: 204940\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 146\u001b[0m\n\u001b[0;32m    144\u001b[0m net\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    145\u001b[0m total_spikes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 146\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_indices\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalid_indices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[7], line 63\u001b[0m, in \u001b[0;36mSpeechCommandsDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     61\u001b[0m file_path, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 63\u001b[0m     waveform, sample_rate \u001b[38;5;241m=\u001b[39m \u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m waveform\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty waveform\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torchaudio\\_backend\\utils.py:205\u001b[0m, in \u001b[0;36mget_load_func.<locals>.load\u001b[1;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load audio data from source.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03mBy default (``normalize=True``, ``channels_first=True``), this function returns Tensor with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m        `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    204\u001b[0m backend \u001b[38;5;241m=\u001b[39m dispatcher(uri, \u001b[38;5;28mformat\u001b[39m, backend)\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torchaudio\\_backend\\soundfile.py:27\u001b[0m, in \u001b[0;36mSoundfileBackend.load\u001b[1;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     19\u001b[0m     uri: Union[BinaryIO, \u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     buffer_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4096\u001b[39m,\n\u001b[0;32m     26\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msoundfile_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torchaudio\\_backend\\soundfile_backend.py:221\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filepath, frame_offset, num_frames, normalize, channels_first, format)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;129m@_requires_soundfile\u001b[39m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m    141\u001b[0m     filepath: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mformat\u001b[39m: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    147\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m    148\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load audio data from file.\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \n\u001b[0;32m    150\u001b[0m \u001b[38;5;124;03m    Note:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;124;03m            `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msoundfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file_:\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m file_\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWAV\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m normalize:\n\u001b[0;32m    223\u001b[0m             dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\soundfile.py:690\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bitrate_mode \u001b[38;5;241m=\u001b[39m bitrate_mode\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    689\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\soundfile.py:1242\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call the appropriate sf_open*() function from libsndfile.\"\"\"\u001b[39;00m\n\u001b[0;32m   1241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file, (_unicode, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[1;32m-> 1242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_os\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1243\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m   1244\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile exists: \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n",
      "File \u001b[1;32m<frozen genericpath>:30\u001b[0m, in \u001b[0;36misfile\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import snntorch as snn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from snntorch import surrogate\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "num_steps = 100  # Number of time steps (frames)\n",
    "num_inputs = 13  # 13 MFCC coefficients per frame\n",
    "num_hidden = 256  # Increased for better capacity\n",
    "num_outputs = 10  # 10 command words\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 20\n",
    "patience = 5\n",
    "beta = 0.95  # Adjusted for longer memory\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Check dataset\n",
    "dataset_dir = \"speech_commands_v0.02\"\n",
    "if not os.path.exists(dataset_dir):\n",
    "    print(\"Please download speech_commands_v0.02.tar.gz from http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz and extract to 'speech_commands_v0.02'\")\n",
    "    exit()\n",
    "\n",
    "# Custom Dataset for Google Speech Commands\n",
    "class SpeechCommandsDataset(Dataset):\n",
    "    def __init__(self, root=\"speech_commands_v0.02\", train=True, target_words=[\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"]):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.target_words = target_words\n",
    "        self.transform = torchaudio.transforms.MFCC(\n",
    "            sample_rate=16000,\n",
    "            n_mfcc=13,\n",
    "            melkwargs={\n",
    "                'n_fft': 400,\n",
    "                'hop_length': 160,\n",
    "                'f_min': 20,\n",
    "                'f_max': 4000,\n",
    "                'n_mels': 40\n",
    "            }\n",
    "        )\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        for word in os.listdir(root):\n",
    "            if word in target_words:\n",
    "                word_dir = os.path.join(root, word)\n",
    "                for file in os.listdir(word_dir):\n",
    "                    if file.endswith(\".wav\"):\n",
    "                        file_path = os.path.join(word_dir, file)\n",
    "                        label = target_words.index(word)\n",
    "                        self.data.append(file_path)\n",
    "                        self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.data[idx], self.labels[idx]\n",
    "        try:\n",
    "            waveform, sample_rate = torchaudio.load(file_path)\n",
    "            if waveform.numel() == 0:\n",
    "                raise ValueError(\"Empty waveform\")\n",
    "            if sample_rate != 16000:\n",
    "                resampler = torchaudio.transforms.Resample(sample_rate, 16000)\n",
    "                waveform = resampler(waveform)\n",
    "            mfcc = self.transform(waveform)\n",
    "            if mfcc.dim() == 3 and mfcc.shape[0] == 1:\n",
    "                mfcc = mfcc.squeeze(0)  # Shape: [13, num_frames]\n",
    "            num_frames = mfcc.shape[1]\n",
    "            if num_frames < 100:\n",
    "                pad_width = 100 - num_frames\n",
    "                mfcc = torch.nn.functional.pad(mfcc, (0, pad_width))\n",
    "            elif num_frames > 100:\n",
    "                mfcc = mfcc[:, :100]\n",
    "            mfcc = mfcc.transpose(0, 1)  # Shape: [100, 13]\n",
    "            return mfcc, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "            return torch.zeros(100, 13), -1  # Dummy tensor and label\n",
    "\n",
    "# Custom collate function\n",
    "def collate_fn(batch):\n",
    "    data = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "    valid_indices = [i for i, target in enumerate(targets) if target != -1]\n",
    "    if not valid_indices:\n",
    "        return torch.zeros(1, 100, 13), torch.zeros(1, dtype=torch.long)\n",
    "    data = [data[i] for i in valid_indices]\n",
    "    targets = [targets[i] for i in valid_indices]\n",
    "    data = torch.stack(data)\n",
    "    targets = torch.tensor(targets)\n",
    "    return data, targets\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = SpeechCommandsDataset(train=True)\n",
    "test_dataset = SpeechCommandsDataset(train=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# SNN Model\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self, num_inputs=13, num_hidden=256, num_classes=10, beta=0.95):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.lif1 = snn.Leaky(beta=beta, spike_grad=surrogate.fast_sigmoid(slope=25))\n",
    "        self.fc2 = nn.Linear(num_hidden, num_classes)\n",
    "        self.lif2 = snn.Leaky(beta=beta, spike_grad=surrogate.fast_sigmoid(slope=25))\n",
    "        for layer in [self.fc1, self.fc2]:\n",
    "            nn.init.xavier_uniform_(layer.weight, gain=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(1)\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        spk1_rec = []\n",
    "        spk2_rec = []\n",
    "        mem2_rec = []  # Added to store membrane potentials\n",
    "\n",
    "        for step in range(x.size(0)):  # x: [num_steps, batch_size, 13]\n",
    "            cur1 = self.fc1(x[step])  # x[step]: [batch_size, 13]\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk1_rec.append(spk1)\n",
    "            spk2_rec.append(spk2)\n",
    "            mem2_rec.append(mem2)  # Store mem2 at each step\n",
    "\n",
    "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)  # [num_steps, batch_size, num_classes]\n",
    "\n",
    "# Instantiate model and optimizer\n",
    "net = SNN().to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "best_val_accuracy = 0.0\n",
    "epochs_no_improve = 0\n",
    "accuracies, val_accuracies, losses, total_spikes_list = [], [], [], []\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    total_spikes = 0\n",
    "    for data, targets in train_loader:\n",
    "        valid_indices = targets != -1\n",
    "        if not valid_indices.any():\n",
    "            continue\n",
    "        data = data[valid_indices]\n",
    "        targets = targets[valid_indices]\n",
    "        data, targets = data.to(device), targets.to(device)  # data: [batch_size, 100, 13]\n",
    "        batch_size_actual = data.size(0)\n",
    "\n",
    "        # Normalize MFCCs per sample to [0, 1]\n",
    "        data_flat = data.view(batch_size_actual, -1)  # [batch_size, 1300]\n",
    "        data_min = data_flat.min(dim=1, keepdim=True)[0].unsqueeze(2)  # [batch_size, 1, 1]\n",
    "        data_max = data_flat.max(dim=1, keepdim=True)[0].unsqueeze(2)  # [batch_size, 1, 1]\n",
    "        data = (data - data_min) / (data_max - data_min + 1e-8)\n",
    "        data = torch.clamp(data, 0, 1)  # [batch_size, 100, 13]\n",
    "\n",
    "        # Generate spikes: [num_steps, batch_size, 13]\n",
    "        spike_data = (torch.rand(num_steps, batch_size_actual, num_inputs, device=device) <\n",
    "                      data.permute(1, 0, 2) * 0.5).float()  # Increased scaling factor to 0.5\n",
    "\n",
    "        # Forward pass\n",
    "        outputs, _ = net(spike_data)\n",
    "        spk_count = outputs.sum(dim=0)  # Sum over time steps: [batch_size, num_classes]\n",
    "        loss = criterion(spk_count, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=3.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        correct = (spk_count.argmax(dim=1) == targets).sum().item()\n",
    "        accuracy = correct / batch_size_actual\n",
    "        total_spikes += outputs.sum().item()\n",
    "\n",
    "    scheduler.step()\n",
    "    losses.append(loss.item())\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    # Validation\n",
    "    net.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    val_total_spikes = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            valid_indices = targets != -1\n",
    "            if not valid_indices.any():\n",
    "                continue\n",
    "            data = data[valid_indices]\n",
    "            targets = targets[valid_indices]\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            batch_size_actual = data.size(0)\n",
    "\n",
    "            # Normalize and generate spikes (same as training)\n",
    "            data_flat = data.view(batch_size_actual, -1)\n",
    "            data_min = data_flat.min(dim=1, keepdim=True)[0].unsqueeze(2)\n",
    "            data_max = data_flat.max(dim=1, keepdim=True)[0].unsqueeze(2)\n",
    "            data = (data - data_min) / (data_max - data_min + 1e-8)\n",
    "            data = torch.clamp(data, 0, 1)\n",
    "            spike_data = (torch.rand(num_steps, batch_size_actual, num_inputs, device=device) <\n",
    "                          data.permute(1, 0, 2) * 0.5).float()\n",
    "            outputs, _ = net(spike_data)\n",
    "            spk_count = outputs.sum(dim=0)\n",
    "            total_correct += (spk_count.argmax(dim=1) == targets).sum().item()\n",
    "            total_samples += batch_size_actual\n",
    "            val_total_spikes += outputs.sum().item()\n",
    "\n",
    "        val_accuracy = total_correct / total_samples if total_samples > 0 else 0.0\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        total_spikes_list.append(val_total_spikes)\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}, Total Spikes: {val_total_spikes:.0f}\")\n",
    "\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(accuracies, label=\"Train Accuracy\")\n",
    "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(losses, label=\"Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(total_spikes_list, label=\"Total Spikes\")\n",
    "plt.title(\"Total Spikes\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"baseline_snn_results.png\")\n",
    "plt.show()\n",
    "\n",
    "# Final summary\n",
    "final_val_accuracy = max(val_accuracies) if val_accuracies else 0.0\n",
    "final_total_spikes = total_spikes_list[val_accuracies.index(final_val_accuracy)] if val_accuracies else 0\n",
    "energy = final_total_spikes * 20 / 1e6  # µJ\n",
    "print(\"\\nBaseline SNN Final Results:\")\n",
    "print(f\"Peak Validation Accuracy: {final_val_accuracy:.2%}\")\n",
    "print(f\"Total Spikes at Peak Accuracy: {final_total_spikes:.0f}\")\n",
    "print(f\"Energy Consumption: {energy:.2f} µJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (64) must match the size of tensor b (100) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 185\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# Weighted sum of spikes (emphasize later time steps)\u001b[39;00m\n\u001b[0;32m    184\u001b[0m weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, steps\u001b[38;5;241m=\u001b[39mnum_steps, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 185\u001b[0m spk_count \u001b[38;5;241m=\u001b[39m (\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# [batch_size, num_classes]\u001b[39;00m\n\u001b[0;32m    186\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(spk_count, targets)\n\u001b[0;32m    187\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (100) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import snntorch as snn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from snntorch import surrogate\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "num_steps = 100  # Number of time steps (frames)\n",
    "num_inputs = 13  # 13 MFCC coefficients per frame\n",
    "num_hidden = 512  # Increased for better capacity\n",
    "num_outputs = 10  # 10 command words\n",
    "learning_rate = 5e-3  # Increased learning rate\n",
    "num_epochs = 20\n",
    "patience = 5\n",
    "beta = 0.95  # Adjusted for longer memory\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Check dataset\n",
    "dataset_dir = \"speech_commands_v0.02\"\n",
    "if not os.path.exists(dataset_dir):\n",
    "    print(\"Please download speech_commands_v0.02.tar.gz from http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz and extract to 'speech_commands_v0.02'\")\n",
    "    exit()\n",
    "\n",
    "# Custom Dataset for Google Speech Commands\n",
    "class SpeechCommandsDataset(Dataset):\n",
    "    def __init__(self, root=\"speech_commands_v0.02\", train=True, target_words=[\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"]):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.target_words = target_words\n",
    "        self.transform = torchaudio.transforms.MFCC(\n",
    "            sample_rate=16000,\n",
    "            n_mfcc=13,\n",
    "            melkwargs={\n",
    "                'n_fft': 400,\n",
    "                'hop_length': 160,\n",
    "                'f_min': 20,\n",
    "                'f_max': 4000,\n",
    "                'n_mels': 40\n",
    "            }\n",
    "        )\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        for word in os.listdir(root):\n",
    "            if word in target_words:\n",
    "                word_dir = os.path.join(root, word)\n",
    "                for file in os.listdir(word_dir):\n",
    "                    if file.endswith(\".wav\"):\n",
    "                        file_path = os.path.join(word_dir, file)\n",
    "                        label = target_words.index(word)\n",
    "                        self.data.append(file_path)\n",
    "                        self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.data[idx], self.labels[idx]\n",
    "        try:\n",
    "            waveform, sample_rate = torchaudio.load(file_path)\n",
    "            if waveform.numel() == 0:\n",
    "                raise ValueError(\"Empty waveform\")\n",
    "            if sample_rate != 16000:\n",
    "                resampler = torchaudio.transforms.Resample(sample_rate, 16000)\n",
    "                waveform = resampler(waveform)\n",
    "            # Add noise augmentation for training\n",
    "            if self.train:\n",
    "                noise = torch.randn_like(waveform) * 0.005\n",
    "                waveform = waveform + noise\n",
    "            mfcc = self.transform(waveform)\n",
    "            if mfcc.dim() == 3 and mfcc.shape[0] == 1:\n",
    "                mfcc = mfcc.squeeze(0)  # Shape: [13, num_frames]\n",
    "            num_frames = mfcc.shape[1]\n",
    "            if num_frames < 100:\n",
    "                pad_width = 100 - num_frames\n",
    "                mfcc = torch.nn.functional.pad(mfcc, (0, pad_width))\n",
    "            elif num_frames > 100:\n",
    "                mfcc = mfcc[:, :100]\n",
    "            mfcc = mfcc.transpose(0, 1)  # Shape: [100, 13]\n",
    "            return mfcc, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "            return torch.zeros(100, 13), -1  # Dummy tensor and label\n",
    "\n",
    "# Custom collate function\n",
    "def collate_fn(batch):\n",
    "    data = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "    valid_indices = [i for i, target in enumerate(targets) if target != -1]\n",
    "    if not valid_indices:\n",
    "        return torch.zeros(1, 100, 13), torch.zeros(1, dtype=torch.long)\n",
    "    data = [data[i] for i in valid_indices]\n",
    "    targets = [targets[i] for i in valid_indices]\n",
    "    data = torch.stack(data)\n",
    "    targets = torch.tensor(targets)\n",
    "    return data, targets\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = SpeechCommandsDataset(train=True)\n",
    "test_dataset = SpeechCommandsDataset(train=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# SNN Model with Convolution\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self, num_inputs=13, num_hidden=512, num_classes=10, beta=0.95):\n",
    "        super().__init__()\n",
    "        # 1D Convolution to capture local patterns in MFCC frames\n",
    "        self.conv1 = nn.Conv1d(in_channels=num_inputs, out_channels=32, kernel_size=5, padding=2)\n",
    "        self.lif_conv = snn.Leaky(beta=beta, spike_grad=surrogate.fast_sigmoid(slope=25))\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(32, num_hidden)  # Input is 32 features per step\n",
    "        self.lif1 = snn.Leaky(beta=beta, spike_grad=surrogate.fast_sigmoid(slope=25))\n",
    "        self.fc2 = nn.Linear(num_hidden, num_classes)\n",
    "        self.lif2 = snn.Leaky(beta=beta, spike_grad=surrogate.fast_sigmoid(slope=25))\n",
    "        for layer in [self.conv1, self.fc1, self.fc2]:\n",
    "            if hasattr(layer, 'weight'):\n",
    "                nn.init.xavier_uniform_(layer.weight, gain=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(1)\n",
    "        mem_conv = self.lif_conv.init_leaky()\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "\n",
    "        # Process the entire sequence with convolution\n",
    "        conv_in = x.transpose(1, 2)  # [num_steps, batch_size, 13] -> [batch_size, 13, num_steps]\n",
    "        conv_out = self.conv1(conv_in)  # [batch_size, 32, num_steps]\n",
    "        conv_out = conv_out.transpose(1, 2)  # [batch_size, num_steps, 32]\n",
    "\n",
    "        spk2_rec = []\n",
    "        mem2_rec = []\n",
    "\n",
    "        for step in range(conv_out.size(1)):  # Iterate over num_steps\n",
    "            spk_conv, mem_conv = self.lif_conv(conv_out[:, step, :], mem_conv)  # [batch_size, 32]\n",
    "            cur1 = self.fc1(spk_conv)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk2_rec.append(spk2)\n",
    "            mem2_rec.append(mem2)\n",
    "\n",
    "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)  # [num_steps, batch_size, num_classes]\n",
    "\n",
    "# Instantiate model and optimizer\n",
    "net = SNN().to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "best_val_accuracy = 0.0\n",
    "epochs_no_improve = 0\n",
    "accuracies, val_accuracies, losses, total_spikes_list = [], [], [], []\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    total_spikes = 0\n",
    "    for data, targets in train_loader:\n",
    "        valid_indices = targets != -1\n",
    "        if not valid_indices.any():\n",
    "            continue\n",
    "        data = data[valid_indices]\n",
    "        targets = targets[valid_indices]\n",
    "        data, targets = data.to(device), targets.to(device)  # data: [batch_size, 100, 13]\n",
    "        batch_size_actual = data.size(0)\n",
    "\n",
    "        # Normalize MFCCs per sample to [0, 1]\n",
    "        data_flat = data.view(batch_size_actual, -1)  # [batch_size, 1300]\n",
    "        data_min = data_flat.min(dim=1, keepdim=True)[0].unsqueeze(2)  # [batch_size, 1, 1]\n",
    "        data_max = data_flat.max(dim=1, keepdim=True)[0].unsqueeze(2)  # [batch_size, 1, 1]\n",
    "        data = (data - data_min) / (data_max - data_min + 1e-8)\n",
    "        data = torch.clamp(data, 0, 1)  # [batch_size, 100, 13]\n",
    "\n",
    "        # Generate spikes: [num_steps, batch_size, 13]\n",
    "        spike_data = (torch.rand(num_steps, batch_size_actual, num_inputs, device=device) <\n",
    "                      data.permute(1, 0, 2) * 1.0).float()  # Increased scaling factor to 1.0\n",
    "\n",
    "        # Forward pass\n",
    "        outputs, _ = net(spike_data)\n",
    "        # Weighted sum of spikes (emphasize later time steps)\n",
    "        weights = torch.linspace(0.1, 1.0, steps=num_steps, device=device).view(-1, 1, 1)\n",
    "        spk_count = (outputs * weights).sum(dim=0)  # [batch_size, num_classes]\n",
    "        loss = criterion(spk_count, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=3.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        correct = (spk_count.argmax(dim=1) == targets).sum().item()\n",
    "        accuracy = correct / batch_size_actual\n",
    "        total_spikes += outputs.sum().item()\n",
    "\n",
    "    scheduler.step()\n",
    "    losses.append(loss.item())\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    # Validation\n",
    "    net.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    val_total_spikes = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            valid_indices = targets != -1\n",
    "            if not valid_indices.any():\n",
    "                continue\n",
    "            data = data[valid_indices]\n",
    "            targets = targets[valid_indices]\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            batch_size_actual = data.size(0)\n",
    "\n",
    "            # Normalize and generate spikes (same as training)\n",
    "            data_flat = data.view(batch_size_actual, -1)\n",
    "            data_min = data_flat.min(dim=1, keepdim=True)[0].unsqueeze(2)\n",
    "            data_max = data_flat.max(dim=1, keepdim=True)[0].unsqueeze(2)\n",
    "            data = (data - data_min) / (data_max - data_min + 1e-8)\n",
    "            data = torch.clamp(data, 0, 1)\n",
    "            spike_data = (torch.rand(num_steps, batch_size_actual, num_inputs, device=device) <\n",
    "                          data.permute(1, 0, 2) * 1.0).float()\n",
    "            outputs, _ = net(spike_data)\n",
    "            weights = torch.linspace(0.1, 1.0, steps=num_steps, device=device).view(-1, 1, 1)\n",
    "            spk_count = (outputs * weights).sum(dim=0)\n",
    "            total_correct += (spk_count.argmax(dim=1) == targets).sum().item()\n",
    "            total_samples += batch_size_actual\n",
    "            val_total_spikes += outputs.sum().item()\n",
    "\n",
    "        val_accuracy = total_correct / total_samples if total_samples > 0 else 0.0\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        total_spikes_list.append(val_total_spikes)\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}, Total Spikes: {val_total_spikes:.0f}\")\n",
    "\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(accuracies, label=\"Train Accuracy\")\n",
    "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(losses, label=\"Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(total_spikes_list, label=\"Total Spikes\")\n",
    "plt.title(\"Total Spikes\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"baseline_snn_results.png\")\n",
    "plt.show()\n",
    "\n",
    "# Final summary\n",
    "final_val_accuracy = max(val_accuracies) if val_accuracies else 0.0\n",
    "final_total_spikes = total_spikes_list[val_accuracies.index(final_val_accuracy)] if val_accuracies else 0\n",
    "energy = final_total_spikes * 20 / 1e6  # µJ\n",
    "print(\"\\nBaseline SNN Final Results:\")\n",
    "print(f\"Peak Validation Accuracy: {final_val_accuracy:.2%}\")\n",
    "print(f\"Total Spikes at Peak Accuracy: {final_total_spikes:.0f}\")\n",
    "print(f\"Energy Consumption: {energy:.2f} µJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (64) must match the size of tensor b (100) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 185\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# Weighted sum of spikes (emphasize later time steps)\u001b[39;00m\n\u001b[0;32m    184\u001b[0m weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, steps\u001b[38;5;241m=\u001b[39mnum_steps, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mview(num_steps, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 185\u001b[0m weighted_outputs \u001b[38;5;241m=\u001b[39m \u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m  \u001b[38;5;66;03m# [num_steps, batch_size, num_classes]\u001b[39;00m\n\u001b[0;32m    186\u001b[0m spk_count \u001b[38;5;241m=\u001b[39m weighted_outputs\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# [batch_size, num_classes]\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# Debug shapes\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (100) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import snntorch as snn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from snntorch import surrogate\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "num_steps = 100  # Number of time steps (frames)\n",
    "num_inputs = 13  # 13 MFCC coefficients per frame\n",
    "num_hidden = 512  # Increased for better capacity\n",
    "num_outputs = 10  # 10 command words\n",
    "learning_rate = 5e-3  # Increased learning rate\n",
    "num_epochs = 20\n",
    "patience = 5\n",
    "beta = 0.95  # Adjusted for longer memory\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Check dataset\n",
    "dataset_dir = \"speech_commands_v0.02\"\n",
    "if not os.path.exists(dataset_dir):\n",
    "    print(\"Please download speech_commands_v0.02.tar.gz from http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz and extract to 'speech_commands_v0.02'\")\n",
    "    exit()\n",
    "\n",
    "# Custom Dataset for Google Speech Commands\n",
    "class SpeechCommandsDataset(Dataset):\n",
    "    def __init__(self, root=\"speech_commands_v0.02\", train=True, target_words=[\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"]):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.target_words = target_words\n",
    "        self.transform = torchaudio.transforms.MFCC(\n",
    "            sample_rate=16000,\n",
    "            n_mfcc=13,\n",
    "            melkwargs={\n",
    "                'n_fft': 400,\n",
    "                'hop_length': 160,\n",
    "                'f_min': 20,\n",
    "                'f_max': 4000,\n",
    "                'n_mels': 40\n",
    "            }\n",
    "        )\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        for word in os.listdir(root):\n",
    "            if word in target_words:\n",
    "                word_dir = os.path.join(root, word)\n",
    "                for file in os.listdir(word_dir):\n",
    "                    if file.endswith(\".wav\"):\n",
    "                        file_path = os.path.join(word_dir, file)\n",
    "                        label = target_words.index(word)\n",
    "                        self.data.append(file_path)\n",
    "                        self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.data[idx], self.labels[idx]\n",
    "        try:\n",
    "            waveform, sample_rate = torchaudio.load(file_path)\n",
    "            if waveform.numel() == 0:\n",
    "                raise ValueError(\"Empty waveform\")\n",
    "            if sample_rate != 16000:\n",
    "                resampler = torchaudio.transforms.Resample(sample_rate, 16000)\n",
    "                waveform = resampler(waveform)\n",
    "            # Add noise augmentation for training\n",
    "            if self.train:\n",
    "                noise = torch.randn_like(waveform) * 0.005\n",
    "                waveform = waveform + noise\n",
    "            mfcc = self.transform(waveform)\n",
    "            if mfcc.dim() == 3 and mfcc.shape[0] == 1:\n",
    "                mfcc = mfcc.squeeze(0)  # Shape: [13, num_frames]\n",
    "            num_frames = mfcc.shape[1]\n",
    "            if num_frames < 100:\n",
    "                pad_width = 100 - num_frames\n",
    "                mfcc = torch.nn.functional.pad(mfcc, (0, pad_width))\n",
    "            elif num_frames > 100:\n",
    "                mfcc = mfcc[:, :100]\n",
    "            mfcc = mfcc.transpose(0, 1)  # Shape: [100, 13]\n",
    "            return mfcc, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "            return torch.zeros(100, 13), -1  # Dummy tensor and label\n",
    "\n",
    "# Custom collate function\n",
    "def collate_fn(batch):\n",
    "    data = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "    valid_indices = [i for i, target in enumerate(targets) if target != -1]\n",
    "    if not valid_indices:\n",
    "        return torch.zeros(1, 100, 13), torch.zeros(1, dtype=torch.long)\n",
    "    data = [data[i] for i in valid_indices]\n",
    "    targets = [targets[i] for i in valid_indices]\n",
    "    data = torch.stack(data)\n",
    "    targets = torch.tensor(targets)\n",
    "    return data, targets\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = SpeechCommandsDataset(train=True)\n",
    "test_dataset = SpeechCommandsDataset(train=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# SNN Model with Convolution\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self, num_inputs=13, num_hidden=512, num_classes=10, beta=0.95):\n",
    "        super().__init__()\n",
    "        # 1D Convolution to capture local patterns in MFCC frames\n",
    "        self.conv1 = nn.Conv1d(in_channels=num_inputs, out_channels=32, kernel_size=5, padding=2)\n",
    "        self.lif_conv = snn.Leaky(beta=beta, spike_grad=surrogate.fast_sigmoid(slope=25))\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(32, num_hidden)  # Input is 32 features per step\n",
    "        self.lif1 = snn.Leaky(beta=beta, spike_grad=surrogate.fast_sigmoid(slope=25))\n",
    "        self.fc2 = nn.Linear(num_hidden, num_classes)\n",
    "        self.lif2 = snn.Leaky(beta=beta, spike_grad=surrogate.fast_sigmoid(slope=25))\n",
    "        for layer in [self.conv1, self.fc1, self.fc2]:\n",
    "            if hasattr(layer, 'weight'):\n",
    "                nn.init.xavier_uniform_(layer.weight, gain=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(1)\n",
    "        mem_conv = self.lif_conv.init_leaky()\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "\n",
    "        # Process the entire sequence with convolution\n",
    "        conv_in = x.transpose(1, 2)  # [num_steps, batch_size, 13] -> [batch_size, 13, num_steps]\n",
    "        conv_out = self.conv1(conv_in)  # [batch_size, 32, num_steps]\n",
    "        conv_out = conv_out.transpose(1, 2)  # [batch_size, num_steps, 32]\n",
    "\n",
    "        spk2_rec = []\n",
    "        mem2_rec = []\n",
    "\n",
    "        for step in range(conv_out.size(1)):  # Iterate over num_steps\n",
    "            spk_conv, mem_conv = self.lif_conv(conv_out[:, step, :], mem_conv)  # [batch_size, 32]\n",
    "            cur1 = self.fc1(spk_conv)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk2_rec.append(spk2)\n",
    "            mem2_rec.append(mem2)\n",
    "\n",
    "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)  # [num_steps, batch_size, num_classes]\n",
    "\n",
    "# Instantiate model and optimizer\n",
    "net = SNN().to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "best_val_accuracy = 0.0\n",
    "epochs_no_improve = 0\n",
    "accuracies, val_accuracies, losses, total_spikes_list = [], [], [], []\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    total_spikes = 0\n",
    "    for data, targets in train_loader:\n",
    "        valid_indices = targets != -1\n",
    "        if not valid_indices.any():\n",
    "            continue\n",
    "        data = data[valid_indices]\n",
    "        targets = targets[valid_indices]\n",
    "        data, targets = data.to(device), targets.to(device)  # data: [batch_size, 100, 13]\n",
    "        batch_size_actual = data.size(0)\n",
    "\n",
    "        # Normalize MFCCs per sample to [0, 1]\n",
    "        data_flat = data.view(batch_size_actual, -1)  # [batch_size, 1300]\n",
    "        data_min = data_flat.min(dim=1, keepdim=True)[0].unsqueeze(2)  # [batch_size, 1, 1]\n",
    "        data_max = data_flat.max(dim=1, keepdim=True)[0].unsqueeze(2)  # [batch_size, 1, 1]\n",
    "        data = (data - data_min) / (data_max - data_min + 1e-8)\n",
    "        data = torch.clamp(data, 0, 1)  # [batch_size, 100, 13]\n",
    "\n",
    "        # Generate spikes: [num_steps, batch_size, 13]\n",
    "        spike_data = (torch.rand(num_steps, batch_size_actual, num_inputs, device=device) <\n",
    "                      data.permute(1, 0, 2) * 1.0).float()  # Increased scaling factor to 1.0\n",
    "\n",
    "        # Forward pass\n",
    "        outputs, _ = net(spike_data)  # outputs: [num_steps, batch_size, num_classes]\n",
    "        # Weighted sum of spikes (emphasize later time steps)\n",
    "        weights = torch.linspace(0.1, 1.0, steps=num_steps, device=device).view(num_steps, 1, 1)\n",
    "        weighted_outputs = outputs * weights  # [num_steps, batch_size, num_classes]\n",
    "        spk_count = weighted_outputs.sum(dim=0)  # [batch_size, num_classes]\n",
    "        # Debug shapes\n",
    "        if spk_count.size(0) != targets.size(0):\n",
    "            print(f\"Shape mismatch: spk_count {spk_count.size()}, targets {targets.size()}\")\n",
    "            continue\n",
    "        loss = criterion(spk_count, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=3.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        correct = (spk_count.argmax(dim=1) == targets).sum().item()\n",
    "        accuracy = correct / batch_size_actual\n",
    "        total_spikes += outputs.sum().item()\n",
    "\n",
    "    scheduler.step()\n",
    "    losses.append(loss.item())\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    # Validation\n",
    "    net.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    val_total_spikes = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            valid_indices = targets != -1\n",
    "            if not valid_indices.any():\n",
    "                continue\n",
    "            data = data[valid_indices]\n",
    "            targets = targets[valid_indices]\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            batch_size_actual = data.size(0)\n",
    "\n",
    "            # Normalize and generate spikes (same as training)\n",
    "            data_flat = data.view(batch_size_actual, -1)\n",
    "            data_min = data_flat.min(dim=1, keepdim=True)[0].unsqueeze(2)\n",
    "            data_max = data_flat.max(dim=1, keepdim=True)[0].unsqueeze(2)\n",
    "            data = (data - data_min) / (data_max - data_min + 1e-8)\n",
    "            data = torch.clamp(data, 0, 1)\n",
    "            spike_data = (torch.rand(num_steps, batch_size_actual, num_inputs, device=device) <\n",
    "                          data.permute(1, 0, 2) * 1.0).float()\n",
    "            outputs, _ = net(spike_data)\n",
    "            weights = torch.linspace(0.1, 1.0, steps=num_steps, device=device).view(num_steps, 1, 1)\n",
    "            weighted_outputs = outputs * weights\n",
    "            spk_count = weighted_outputs.sum(dim=0)\n",
    "            if spk_count.size(0) != targets.size(0):\n",
    "                print(f\"Validation shape mismatch: spk_count {spk_count.size()}, targets {targets.size()}\")\n",
    "                continue\n",
    "            total_correct += (spk_count.argmax(dim=1) == targets).sum().item()\n",
    "            total_samples += batch_size_actual\n",
    "            val_total_spikes += outputs.sum().item()\n",
    "\n",
    "        val_accuracy = total_correct / total_samples if total_samples > 0 else 0.0\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        total_spikes_list.append(val_total_spikes)\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}, Total Spikes: {val_total_spikes:.0f}\")\n",
    "\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(accuracies, label=\"Train Accuracy\")\n",
    "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(losses, label=\"Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(total_spikes_list, label=\"Total Spikes\")\n",
    "plt.title(\"Total Spikes\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"baseline_snn_results.png\")\n",
    "plt.show()\n",
    "\n",
    "# Final summary\n",
    "final_val_accuracy = max(val_accuracies) if val_accuracies else 0.0\n",
    "final_total_spikes = total_spikes_list[val_accuracies.index(final_val_accuracy)] if val_accuracies else 0\n",
    "energy = final_total_spikes * 20 / 1e6  # µJ\n",
    "print(\"\\nBaseline SNN Final Results:\")\n",
    "print(f\"Peak Validation Accuracy: {final_val_accuracy:.2%}\")\n",
    "print(f\"Total Spikes at Peak Accuracy: {final_total_spikes:.0f}\")\n",
    "print(f\"Energy Consumption: {energy:.2f} µJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 18, 10])\n",
      "targets shape: torch.Size([18])\n",
      "Epoch 1, Loss: 2.3026, Accuracy: 0.0000, Validation Accuracy: 0.1049, Total Spikes: 0\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 18, 10])\n",
      "targets shape: torch.Size([18])\n",
      "Epoch 2, Loss: 2.3026, Accuracy: 0.0556, Validation Accuracy: 0.1049, Total Spikes: 0\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 18, 10])\n",
      "targets shape: torch.Size([18])\n",
      "Epoch 3, Loss: 2.3026, Accuracy: 0.1667, Validation Accuracy: 0.1049, Total Spikes: 0\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 18, 10])\n",
      "targets shape: torch.Size([18])\n",
      "Epoch 4, Loss: 2.3026, Accuracy: 0.1667, Validation Accuracy: 0.1049, Total Spikes: 0\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 18, 10])\n",
      "targets shape: torch.Size([18])\n",
      "Epoch 5, Loss: 2.3026, Accuracy: 0.1111, Validation Accuracy: 0.1049, Total Spikes: 0\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 64, 10])\n",
      "targets shape: torch.Size([64])\n",
      "outputs shape: torch.Size([100, 18, 10])\n",
      "targets shape: torch.Size([18])\n",
      "Epoch 6, Loss: 2.3026, Accuracy: 0.1111, Validation Accuracy: 0.1049, Total Spikes: 0\n",
      "Early stopping triggered after 6 epochs\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline SNN Final Results:\n",
      "Peak Validation Accuracy: 10.49%\n",
      "Total Spikes at Peak Accuracy: 0\n",
      "Energy Consumption: 0.00 µJ\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import snntorch as snn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from snntorch import surrogate\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "num_steps = 100  # Number of time steps (frames)\n",
    "num_inputs = 13  # 13 MFCC coefficients per frame\n",
    "num_hidden = 512  # Increased for better capacity\n",
    "num_outputs = 10  # 10 command words\n",
    "learning_rate = 5e-3  # Increased learning rate\n",
    "num_epochs = 20\n",
    "patience = 5\n",
    "beta = 0.95  # Adjusted for longer memory\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Check dataset\n",
    "dataset_dir = \"speech_commands_v0.02\"\n",
    "if not os.path.exists(dataset_dir):\n",
    "    print(\"Please download speech_commands_v0.02.tar.gz from http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz and extract to 'speech_commands_v0.02'\")\n",
    "    exit()\n",
    "\n",
    "# Custom Dataset for Google Speech Commands\n",
    "class SpeechCommandsDataset(Dataset):\n",
    "    def __init__(self, root=\"speech_commands_v0.02\", train=True, target_words=[\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"]):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.target_words = target_words\n",
    "        self.transform = torchaudio.transforms.MFCC(\n",
    "            sample_rate=16000,\n",
    "            n_mfcc=13,\n",
    "            melkwargs={\n",
    "                'n_fft': 400,\n",
    "                'hop_length': 160,\n",
    "                'f_min': 20,\n",
    "                'f_max': 4000,\n",
    "                'n_mels': 40\n",
    "            }\n",
    "        )\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        for word in os.listdir(root):\n",
    "            if word in target_words:\n",
    "                word_dir = os.path.join(root, word)\n",
    "                for file in os.listdir(word_dir):\n",
    "                    if file.endswith(\".wav\"):\n",
    "                        file_path = os.path.join(word_dir, file)\n",
    "                        label = target_words.index(word)\n",
    "                        self.data.append(file_path)\n",
    "                        self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.data[idx], self.labels[idx]\n",
    "        try:\n",
    "            waveform, sample_rate = torchaudio.load(file_path)\n",
    "            if waveform.numel() == 0:\n",
    "                raise ValueError(\"Empty waveform\")\n",
    "            if sample_rate != 16000:\n",
    "                resampler = torchaudio.transforms.Resample(sample_rate, 16000)\n",
    "                waveform = resampler(waveform)\n",
    "            # Add noise augmentation for training\n",
    "            if self.train:\n",
    "                noise = torch.randn_like(waveform) * 0.005\n",
    "                waveform = waveform + noise\n",
    "            mfcc = self.transform(waveform)\n",
    "            if mfcc.dim() == 3 and mfcc.shape[0] == 1:\n",
    "                mfcc = mfcc.squeeze(0)  # Shape: [13, num_frames]\n",
    "            num_frames = mfcc.shape[1]\n",
    "            if num_frames < 100:\n",
    "                pad_width = 100 - num_frames\n",
    "                mfcc = torch.nn.functional.pad(mfcc, (0, pad_width))\n",
    "            elif num_frames > 100:\n",
    "                mfcc = mfcc[:, :100]\n",
    "            mfcc = mfcc.transpose(0, 1)  # Shape: [100, 13]\n",
    "            return mfcc, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "            return torch.zeros(100, 13), -1  # Dummy tensor and label\n",
    "\n",
    "# Custom collate function\n",
    "def collate_fn(batch):\n",
    "    data = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "    valid_indices = [i for i, target in enumerate(targets) if target != -1]\n",
    "    if not valid_indices:\n",
    "        return torch.zeros(1, 100, 13), torch.zeros(1, dtype=torch.long)\n",
    "    data = [data[i] for i in valid_indices]\n",
    "    targets = [targets[i] for i in valid_indices]\n",
    "    data = torch.stack(data)\n",
    "    targets = torch.tensor(targets)\n",
    "    return data, targets\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = SpeechCommandsDataset(train=True)\n",
    "test_dataset = SpeechCommandsDataset(train=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# SNN Model with Convolution\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self, num_inputs=13, num_hidden=512, num_classes=10, beta=0.95):\n",
    "        super().__init__()\n",
    "        # 1D Convolution to capture local patterns in MFCC frames\n",
    "        self.conv1 = nn.Conv1d(in_channels=num_inputs, out_channels=32, kernel_size=5, padding=2)\n",
    "        self.lif_conv = snn.Leaky(beta=beta, spike_grad=surrogate.fast_sigmoid(slope=25))\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(32, num_hidden)  # Input is 32 features per step\n",
    "        self.lif1 = snn.Leaky(beta=beta, spike_grad=surrogate.fast_sigmoid(slope=25))\n",
    "        self.fc2 = nn.Linear(num_hidden, num_classes)\n",
    "        self.lif2 = snn.Leaky(beta=beta, spike_grad=surrogate.fast_sigmoid(slope=25))\n",
    "        for layer in [self.conv1, self.fc1, self.fc2]:\n",
    "            if hasattr(layer, 'weight'):\n",
    "                nn.init.xavier_uniform_(layer.weight, gain=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(1)\n",
    "        mem_conv = self.lif_conv.init_leaky()\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "\n",
    "        # Process the entire sequence with convolution\n",
    "        conv_in = x.transpose(1, 2)  # [num_steps, batch_size, 13] -> [batch_size, 13, num_steps]\n",
    "        conv_out = self.conv1(conv_in)  # [batch_size, 32, num_steps]\n",
    "        conv_out = conv_out.transpose(1, 2)  # [batch_size, num_steps, 32]\n",
    "\n",
    "        spk2_rec = []\n",
    "        mem2_rec = []\n",
    "\n",
    "        for step in range(conv_out.size(1)):  # Iterate over num_steps\n",
    "            spk_conv, mem_conv = self.lif_conv(conv_out[:, step, :], mem_conv)  # [batch_size, 32]\n",
    "            cur1 = self.fc1(spk_conv)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk2_rec.append(spk2)\n",
    "            mem2_rec.append(mem2)\n",
    "\n",
    "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)  # [num_steps, batch_size, num_classes]\n",
    "\n",
    "# Instantiate model and optimizer\n",
    "net = SNN().to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "best_val_accuracy = 0.0\n",
    "epochs_no_improve = 0\n",
    "accuracies, val_accuracies, losses, total_spikes_list = [], [], [], []\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    total_spikes = 0\n",
    "    for data, targets in train_loader:\n",
    "        valid_indices = targets != -1\n",
    "        if not valid_indices.any():\n",
    "            continue\n",
    "        data = data[valid_indices]\n",
    "        targets = targets[valid_indices]\n",
    "        data, targets = data.to(device), targets.to(device)  # data: [batch_size, 100, 13]\n",
    "        batch_size_actual = data.size(0)\n",
    "\n",
    "        # Normalize MFCCs per sample to [0, 1]\n",
    "        data_flat = data.view(batch_size_actual, -1)  # [batch_size, 1300]\n",
    "        data_min = data_flat.min(dim=1, keepdim=True)[0].unsqueeze(2)  # [batch_size, 1, 1]\n",
    "        data_max = data_flat.max(dim=1, keepdim=True)[0].unsqueeze(2)  # [batch_size, 1, 1]\n",
    "        data = (data - data_min) / (data_max - data_min + 1e-8)\n",
    "        data = torch.clamp(data, 0, 1)  # [batch_size, 100, 13]\n",
    "\n",
    "        # Generate spikes: [num_steps, batch_size, 13]\n",
    "        spike_data = (torch.rand(num_steps, batch_size_actual, num_inputs, device=device) <\n",
    "                      data.permute(1, 0, 2) * 1.0).float()  # Increased scaling factor to 1.0\n",
    "\n",
    "        # Forward pass\n",
    "        outputs, _ = net(spike_data)  # outputs: [num_steps, batch_size, num_classes] or [batch_size, num_steps, num_classes]\n",
    "        # Check and correct outputs shape\n",
    "        if outputs.size(0) == batch_size_actual:\n",
    "            outputs = outputs.permute(1, 0, 2)  # From [batch_size, num_steps, num_classes] to [num_steps, batch_size, num_classes]\n",
    "        # Debug shapes\n",
    "        print(f\"outputs shape: {outputs.shape}\")\n",
    "        print(f\"targets shape: {targets.shape}\")\n",
    "\n",
    "        # Weighted sum of spikes (emphasize later time steps)\n",
    "        weights = torch.linspace(0.1, 1.0, steps=num_steps, device=device).view(num_steps, 1, 1)\n",
    "        weighted_outputs = outputs * weights  # Broadcasting: [num_steps, batch_size, num_classes]\n",
    "        spk_count = weighted_outputs.sum(dim=0)  # [batch_size, num_classes]\n",
    "\n",
    "        # Ensure shapes match for loss computation\n",
    "        if spk_count.size(0) != targets.size(0):\n",
    "            print(f\"Shape mismatch: spk_count {spk_count.size()}, targets {targets.size()}\")\n",
    "            continue\n",
    "        loss = criterion(spk_count, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=3.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        correct = (spk_count.argmax(dim=1) == targets).sum().item()\n",
    "        accuracy = correct / batch_size_actual\n",
    "        total_spikes += outputs.sum().item()\n",
    "\n",
    "    scheduler.step()\n",
    "    losses.append(loss.item())\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    # Validation\n",
    "    net.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    val_total_spikes = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            valid_indices = targets != -1\n",
    "            if not valid_indices.any():\n",
    "                continue\n",
    "            data = data[valid_indices]\n",
    "            targets = targets[valid_indices]\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            batch_size_actual = data.size(0)\n",
    "\n",
    "            # Normalize and generate spikes (same as training)\n",
    "            data_flat = data.view(batch_size_actual, -1)\n",
    "            data_min = data_flat.min(dim=1, keepdim=True)[0].unsqueeze(2)\n",
    "            data_max = data_flat.max(dim=1, keepdim=True)[0].unsqueeze(2)\n",
    "            data = (data - data_min) / (data_max - data_min + 1e-8)\n",
    "            data = torch.clamp(data, 0, 1)\n",
    "            spike_data = (torch.rand(num_steps, batch_size_actual, num_inputs, device=device) <\n",
    "                          data.permute(1, 0, 2) * 1.0).float()\n",
    "            outputs, _ = net(spike_data)\n",
    "            # Check and correct outputs shape\n",
    "            if outputs.size(0) == batch_size_actual:\n",
    "                outputs = outputs.permute(1, 0, 2)  # From [batch_size, num_steps, num_classes] to [num_steps, batch_size, num_classes]\n",
    "            weights = torch.linspace(0.1, 1.0, steps=num_steps, device=device).view(num_steps, 1, 1)\n",
    "            weighted_outputs = outputs * weights\n",
    "            spk_count = weighted_outputs.sum(dim=0)\n",
    "            if spk_count.size(0) != targets.size(0):\n",
    "                print(f\"Validation shape mismatch: spk_count {spk_count.size()}, targets {targets.size()}\")\n",
    "                continue\n",
    "            total_correct += (spk_count.argmax(dim=1) == targets).sum().item()\n",
    "            total_samples += batch_size_actual\n",
    "            val_total_spikes += outputs.sum().item()\n",
    "\n",
    "        val_accuracy = total_correct / total_samples if total_samples > 0 else 0.0\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        total_spikes_list.append(val_total_spikes)\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}, Total Spikes: {val_total_spikes:.0f}\")\n",
    "\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(accuracies, label=\"Train Accuracy\")\n",
    "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(losses, label=\"Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(total_spikes_list, label=\"Total Spikes\")\n",
    "plt.title(\"Total Spikes\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"baseline_snn_results.png\")\n",
    "plt.show()\n",
    "\n",
    "# Final summary\n",
    "final_val_accuracy = max(val_accuracies) if val_accuracies else 0.0\n",
    "final_total_spikes = total_spikes_list[val_accuracies.index(final_val_accuracy)] if val_accuracies else 0\n",
    "energy = final_total_spikes * 20 / 1e6  # µJ\n",
    "print(\"\\nBaseline SNN Final Results:\")\n",
    "print(f\"Peak Validation Accuracy: {final_val_accuracy:.2%}\")\n",
    "print(f\"Total Spikes at Peak Accuracy: {final_total_spikes:.0f}\")\n",
    "print(f\"Energy Consumption: {energy:.2f} µJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 64 is out of bounds for dimension 1 with size 64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 169\u001b[0m\n\u001b[0;32m    166\u001b[0m spike_data \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mrand(num_steps, batch_size_actual, num_inputs, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;241m<\u001b[39m data\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m    168\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspike_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m spk_count \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# [batch_size, num_classes]\u001b[39;00m\n\u001b[0;32m    171\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(spk_count, targets)\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[13], line 127\u001b[0m, in \u001b[0;36mSNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    124\u001b[0m spk2_rec \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_steps):\n\u001b[1;32m--> 127\u001b[0m     step_data \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# [batch_size, 13]\u001b[39;00m\n\u001b[0;32m    128\u001b[0m     conv_in \u001b[38;5;241m=\u001b[39m step_data\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# [batch_size, 13, 1] (channels=13, seq_len=1)\u001b[39;00m\n\u001b[0;32m    129\u001b[0m     conv_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(conv_in)  \u001b[38;5;66;03m# [batch_size, 32, 1]\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 64 is out of bounds for dimension 1 with size 64"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import snntorch as snn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from snntorch import surrogate\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "num_steps = 100  # 100 time steps for 1 second of audio\n",
    "num_inputs = 13  # 13 MFCC features per frame\n",
    "num_hidden = 256  # Increased hidden units\n",
    "num_outputs = 10  # 10 command words\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 15\n",
    "patience = 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Check dataset\n",
    "dataset_dir = \"speech_commands_v0.02\"\n",
    "if not os.path.exists(dataset_dir):\n",
    "    print(\"Please download speech_commands_v0.02.tar.gz from http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz and extract to 'speech_commands_v0.02'\")\n",
    "    exit()\n",
    "\n",
    "# Custom Dataset for Google Speech Commands\n",
    "class SpeechCommandsDataset(Dataset):\n",
    "    def __init__(self, root=\"speech_commands_v0.02\", train=True, target_words=[\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"]):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.target_words = target_words\n",
    "        self.transform = torchaudio.transforms.MFCC(\n",
    "            sample_rate=16000,\n",
    "            n_mfcc=13,\n",
    "            melkwargs={\n",
    "                'n_fft': 400,\n",
    "                'hop_length': 160,\n",
    "                'f_min': 20,\n",
    "                'f_max': 4000,\n",
    "                'n_mels': 40\n",
    "            }\n",
    "        )\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        for word in os.listdir(root):\n",
    "            if word in target_words:\n",
    "                word_dir = os.path.join(root, word)\n",
    "                for file in os.listdir(word_dir):\n",
    "                    if file.endswith(\".wav\"):\n",
    "                        file_path = os.path.join(word_dir, file)\n",
    "                        label = target_words.index(word)\n",
    "                        self.data.append(file_path)\n",
    "                        self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.data[idx], self.labels[idx]\n",
    "        try:\n",
    "            waveform, sample_rate = torchaudio.load(file_path)\n",
    "            if waveform.numel() == 0:\n",
    "                raise ValueError(\"Empty waveform\")\n",
    "            if sample_rate != 16000:\n",
    "                resampler = torchaudio.transforms.Resample(sample_rate, 16000)\n",
    "                waveform = resampler(waveform)\n",
    "            mfcc = self.transform(waveform)\n",
    "            if mfcc.dim() == 3 and mfcc.shape[0] == 1:\n",
    "                mfcc = mfcc.squeeze(0)  # Shape: [13, num_frames]\n",
    "            num_frames = mfcc.shape[1]\n",
    "            if num_frames < 100:\n",
    "                pad_width = 100 - num_frames\n",
    "                mfcc = torch.nn.functional.pad(mfcc, (0, pad_width))\n",
    "            elif num_frames > 100:\n",
    "                mfcc = mfcc[:, :100]\n",
    "            mfcc = mfcc.transpose(0, 1)  # Shape: [100, 13]\n",
    "            return mfcc, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "            return torch.zeros(100, 13), -1  # Dummy tensor and label\n",
    "\n",
    "# Custom collate function\n",
    "def collate_fn(batch):\n",
    "    data = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "    valid_indices = [i for i, target in enumerate(targets) if target != -1]\n",
    "    if not valid_indices:\n",
    "        return torch.zeros(1, 100, 13), torch.zeros(1, dtype=torch.long)\n",
    "    data = [data[i] for i in valid_indices]\n",
    "    targets = [targets[i] for i in valid_indices]\n",
    "    data = torch.stack(data)\n",
    "    targets = torch.tensor(targets)\n",
    "    return data, targets\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = SpeechCommandsDataset(train=True)\n",
    "test_dataset = SpeechCommandsDataset(train=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# Surrogate gradient\n",
    "spike_grad = surrogate.fast_sigmoid(slope=25)\n",
    "\n",
    "# Improved SNN with Convolutional Layer\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=13, out_channels=32, kernel_size=5, padding=2)\n",
    "        self.lif_conv = snn.Leaky(beta=0.95, spike_grad=spike_grad)\n",
    "        self.fc1 = nn.Linear(32, num_hidden)\n",
    "        self.lif1 = snn.Leaky(beta=0.95, spike_grad=spike_grad)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lif2 = snn.Leaky(beta=0.95, spike_grad=spike_grad)\n",
    "        for layer in [self.conv1, self.fc1, self.fc2]:\n",
    "            if hasattr(layer, 'weight'):\n",
    "                nn.init.xavier_uniform_(layer.weight, gain=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)  # x: [batch_size, num_steps, num_inputs]\n",
    "        mem_conv = self.lif_conv.init_leaky()\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        spk2_rec = []\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            step_data = x[:, step, :]  # [batch_size, 13]\n",
    "            conv_in = step_data.unsqueeze(2)  # [batch_size, 13, 1] (channels=13, seq_len=1)\n",
    "            conv_out = self.conv1(conv_in)  # [batch_size, 32, 1]\n",
    "            spk_conv, mem_conv = self.lif_conv(conv_out, mem_conv)\n",
    "            flat = spk_conv.view(batch_size, -1)  # [batch_size, 32]\n",
    "            cur1 = self.fc1(flat)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk2_rec.append(spk2)\n",
    "\n",
    "        return torch.stack(spk2_rec, dim=0)  # [num_steps, batch_size, num_classes]\n",
    "\n",
    "# Instantiate model and optimizer\n",
    "net = SNN().to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "best_val_accuracy = 0.0\n",
    "epochs_no_improve = 0\n",
    "accuracies, val_accuracies, losses, total_spikes_list = [], [], [], []\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    total_spikes = 0\n",
    "    for data, targets in train_loader:\n",
    "        valid_indices = targets != -1\n",
    "        if not valid_indices.any():\n",
    "            continue\n",
    "        data = data[valid_indices]\n",
    "        targets = targets[valid_indices]\n",
    "        data, targets = data.to(device), targets.to(device)  # data: [batch_size, 100, 13]\n",
    "        batch_size_actual = data.size(0)\n",
    "\n",
    "        # Normalize MFCCs per sample\n",
    "        data = (data - data.min()) / (data.max() - data.min() + 1e-8)\n",
    "\n",
    "        # Generate spikes: [num_steps, batch_size, 13]\n",
    "        spike_data = (torch.rand(num_steps, batch_size_actual, num_inputs, device=device) < data.permute(1, 0, 2) * 0.5).float()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = net(spike_data)\n",
    "        spk_count = outputs.sum(dim=0)  # [batch_size, num_classes]\n",
    "        loss = criterion(spk_count, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=3.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        correct = (spk_count.argmax(dim=1) == targets).sum().item()\n",
    "        accuracy = correct / batch_size_actual\n",
    "        total_spikes += outputs.sum().item()\n",
    "\n",
    "    scheduler.step()\n",
    "    losses.append(loss.item())\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    # Validation\n",
    "    net.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    val_total_spikes = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            valid_indices = targets != -1\n",
    "            if not valid_indices.any():\n",
    "                continue\n",
    "            data = data[valid_indices]\n",
    "            targets = targets[valid_indices]\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            batch_size_actual = data.size(0)\n",
    "\n",
    "            # Normalize MFCCs\n",
    "            data = (data - data.min()) / (data.max() - data.min() + 1e-8)\n",
    "\n",
    "            # Generate spikes\n",
    "            spike_data = (torch.rand(num_steps, batch_size_actual, num_inputs, device=device) < data.permute(1, 0, 2) * 0.5).float()\n",
    "            outputs = net(spike_data)\n",
    "            spk_count = outputs.sum(dim=0)\n",
    "            total_correct += (spk_count.argmax(dim=1) == targets).sum().item()\n",
    "            total_samples += batch_size_actual\n",
    "            val_total_spikes += outputs.sum().item()\n",
    "\n",
    "        val_accuracy = total_correct / total_samples if total_samples > 0 else 0.0\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        total_spikes_list.append(val_total_spikes)\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}, Total Spikes: {val_total_spikes:.0f}\")\n",
    "\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(accuracies, label=\"Train Accuracy\")\n",
    "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(losses, label=\"Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(total_spikes_list, label=\"Total Spikes\")\n",
    "plt.title(\"Total Spikes\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"improved_snn_results.png\")\n",
    "\n",
    "# Final summary\n",
    "final_val_accuracy = max(val_accuracies) if val_accuracies else 0.0\n",
    "final_total_spikes = total_spikes_list[val_accuracies.index(final_val_accuracy)] if val_accuracies else 0\n",
    "energy = final_total_spikes * 20 / 1e6  # µJ\n",
    "print(\"\\nImproved SNN Final Results:\")\n",
    "print(f\"Peak Validation Accuracy: {final_val_accuracy:.2%}\")\n",
    "print(f\"Total Spikes at Peak Accuracy: {final_total_spikes:.0f}\")\n",
    "print(f\"Energy Consumption: {energy:.2f} µJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 2.3026, Validation Accuracy: 0.1049\n",
      "Epoch 2 - Loss: 2.3026, Validation Accuracy: 0.1049\n",
      "Epoch 3 - Loss: 2.3026, Validation Accuracy: 0.1049\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 166\u001b[0m\n\u001b[0;32m    163\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(spk_count, targets)\n\u001b[0;32m    165\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 166\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    169\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\autograd\\function.py:277\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mBackwardCFunction\u001b[39;00m(_C\u001b[38;5;241m.\u001b[39m_FunctionBase, FunctionCtx, _HookMixin):\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;66;03m# _forward_cls is defined by derived class\u001b[39;00m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;66;03m# The user should define either backward or vjp but never both.\u001b[39;00m\n\u001b[0;32m    280\u001b[0m         backward_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cls\u001b[38;5;241m.\u001b[39mbackward  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    281\u001b[0m         vjp_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cls\u001b[38;5;241m.\u001b[39mvjp  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- Imports ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import snntorch as snn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from snntorch import surrogate\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "batch_size = 64\n",
    "num_steps = 100\n",
    "num_inputs = 13\n",
    "num_hidden = 256\n",
    "num_outputs = 10\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 15\n",
    "patience = 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Dataset path ---\n",
    "dataset_dir = \"speech_commands_v0.02\"\n",
    "if not os.path.exists(dataset_dir):\n",
    "    print(\"Download the dataset manually from:\")\n",
    "    print(\"http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz\")\n",
    "    exit()\n",
    "\n",
    "# --- Poisson Spike Generator ---\n",
    "def poisson_spike_train(data, num_steps):\n",
    "    batch_size, seq_len, num_inputs = data.shape  # [batch_size, 100, 13]\n",
    "    repeated_data = data.unsqueeze(1).repeat(1, num_steps, 1, 1)  # [batch_size, num_steps, 100, 13]\n",
    "    spikes = torch.rand_like(repeated_data) < repeated_data\n",
    "    return spikes.float()\n",
    "\n",
    "# --- Custom Dataset ---\n",
    "class SpeechCommandsDataset(Dataset):\n",
    "    def __init__(self, root, target_words, train=True):\n",
    "        self.root = root\n",
    "        self.target_words = target_words\n",
    "        self.transform = torchaudio.transforms.MFCC(\n",
    "            sample_rate=16000,\n",
    "            n_mfcc=13,\n",
    "            melkwargs={'n_fft': 400, 'hop_length': 160, 'f_min': 20, 'f_max': 4000, 'n_mels': 40}\n",
    "        )\n",
    "        self.data, self.labels = [], []\n",
    "        for word in os.listdir(root):\n",
    "            if word in target_words:\n",
    "                for file in os.listdir(os.path.join(root, word)):\n",
    "                    if file.endswith('.wav'):\n",
    "                        self.data.append(os.path.join(root, word, file))\n",
    "                        self.labels.append(target_words.index(word))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.data[idx], self.labels[idx]\n",
    "        try:\n",
    "            waveform, sample_rate = torchaudio.load(file_path)\n",
    "            if waveform.numel() == 0: raise ValueError(\"Empty waveform\")\n",
    "            if sample_rate != 16000:\n",
    "                waveform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)(waveform)\n",
    "            mfcc = self.transform(waveform)\n",
    "            if mfcc.dim() == 3 and mfcc.shape[0] == 1:\n",
    "                mfcc = mfcc.squeeze(0)\n",
    "            mfcc = mfcc.transpose(0, 1)  # [time, 13]\n",
    "\n",
    "            # Pad or crop to exactly 100 frames\n",
    "            if mfcc.shape[0] < 100:\n",
    "                pad_size = 100 - mfcc.shape[0]\n",
    "                mfcc = torch.nn.functional.pad(mfcc, (0, 0, 0, pad_size))\n",
    "            elif mfcc.shape[0] > 100:\n",
    "                mfcc = mfcc[:100]\n",
    "\n",
    "            return mfcc, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\")\n",
    "            return torch.zeros(100, 13), -1\n",
    "\n",
    "# --- Collate Function ---\n",
    "def collate_fn(batch):\n",
    "    data = [item[0] for item in batch]\n",
    "    labels = [item[1] for item in batch]\n",
    "    valid = [i for i, lbl in enumerate(labels) if lbl != -1]\n",
    "    if not valid:\n",
    "        return torch.zeros(1, 100, 13), torch.zeros(1, dtype=torch.long)\n",
    "    data = torch.stack([data[i] for i in valid])\n",
    "    labels = torch.tensor([labels[i] for i in valid])\n",
    "    return data, labels\n",
    "\n",
    "# --- Loaders ---\n",
    "target_words = [\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"]\n",
    "train_dataset = SpeechCommandsDataset(dataset_dir, target_words, train=True)\n",
    "test_dataset = SpeechCommandsDataset(dataset_dir, target_words, train=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# --- Surrogate gradient ---\n",
    "spike_grad = surrogate.fast_sigmoid(slope=25)\n",
    "\n",
    "# --- SNN Model ---\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(13, 32, kernel_size=5, padding=2)\n",
    "        self.lif_conv = snn.Leaky(beta=0.95, spike_grad=spike_grad)\n",
    "        self.fc1 = nn.Linear(32, num_hidden)\n",
    "        self.lif1 = snn.Leaky(beta=0.95, spike_grad=spike_grad)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lif2 = snn.Leaky(beta=0.95, spike_grad=spike_grad)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, num_steps, seq_len, num_inputs = x.shape\n",
    "        mem_conv = self.lif_conv.init_leaky()\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        spk2_rec = []\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            step_data = x[:, step]  # [batch_size, 100, 13]\n",
    "            step_data = step_data.transpose(1, 2)  # [batch_size, 13, 100]\n",
    "            conv_out = self.conv1(step_data)  # [batch_size, 32, 100]\n",
    "            conv_out = conv_out.mean(dim=2)  # Pooling: mean over time\n",
    "            spk_conv, mem_conv = self.lif_conv(conv_out, mem_conv)\n",
    "            cur1 = self.fc1(spk_conv)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk2_rec.append(spk2)\n",
    "\n",
    "        return torch.stack(spk2_rec)  # [num_steps, batch_size, num_classes]\n",
    "\n",
    "# --- Model setup ---\n",
    "net = SNN().to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# --- Training Loop ---\n",
    "best_val_accuracy = 0.0\n",
    "epochs_no_improve = 0\n",
    "accuracies, val_accuracies, losses, total_spikes_list = [], [], [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    for data, targets in train_loader:\n",
    "        valid = targets != -1\n",
    "        if not valid.any():\n",
    "            continue\n",
    "        data, targets = data[valid].to(device), targets[valid].to(device)\n",
    "\n",
    "        # Normalize input\n",
    "        data = (data - data.min()) / (data.max() - data.min() + 1e-8)\n",
    "\n",
    "        # Generate Poisson spike trains\n",
    "        spike_data = poisson_spike_train(data, num_steps=num_steps)  # [batch, num_steps, 100, 13]\n",
    "\n",
    "        # Forward\n",
    "        outputs = net(spike_data)\n",
    "        spk_count = outputs.sum(dim=0)  # [batch_size, num_classes]\n",
    "        loss = criterion(spk_count, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    # --- Validation ---\n",
    "    net.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            valid = targets != -1\n",
    "            if not valid.any():\n",
    "                continue\n",
    "            data, targets = data[valid].to(device), targets[valid].to(device)\n",
    "\n",
    "            data = (data - data.min()) / (data.max() - data.min() + 1e-8)\n",
    "            spike_data = poisson_spike_train(data, num_steps=num_steps)\n",
    "\n",
    "            outputs = net(spike_data)\n",
    "            spk_count = outputs.sum(dim=0)\n",
    "            total_correct += (spk_count.argmax(dim=1) == targets).sum().item()\n",
    "            total_samples += targets.size(0)\n",
    "\n",
    "    val_accuracy = total_correct / total_samples\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} - Loss: {loss.item():.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n",
    "# --- Results ---\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(losses, label=\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training Loss\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Validation Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nBest Validation Accuracy: {:.2%}\".format(best_val_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [20, 101] at entry 0 and [20, 76] at entry 7",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 139\u001b[0m\n\u001b[0;32m    136\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    137\u001b[0m total_spikes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 139\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspike_input\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpoisson_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_steps\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:144\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtransposed\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:144\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:121\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:174\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    172\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    173\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [20, 101] at entry 0 and [20, 76] at entry 7"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ------------------------\n",
    "# Data Loading\n",
    "# ------------------------\n",
    "\n",
    "class SpeechCommandsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, subset):\n",
    "        self.dataset = torchaudio.datasets.SPEECHCOMMANDS(\n",
    "            \"./\", download=True, subset=subset\n",
    "        )\n",
    "        self.labels = sorted(list(set(dat[2] for dat in self.dataset)))\n",
    "        self.label_to_index = {label: i for i, label in enumerate(self.labels)}\n",
    "        self.transform = T.MFCC(\n",
    "            sample_rate=16000,\n",
    "            n_mfcc=20,\n",
    "            melkwargs={\"n_fft\": 400, \"hop_length\": 160, \"n_mels\": 40}\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        waveform, sample_rate, label, *_ = self.dataset[idx]\n",
    "        mfcc = self.transform(waveform).squeeze(0)  # (MFCC, Time)\n",
    "        mfcc = (mfcc - mfcc.min()) / (mfcc.max() - mfcc.min() + 1e-8)\n",
    "        mfcc = mfcc * 5.0\n",
    "        mfcc = torch.clamp(mfcc, 0, 1)\n",
    "        return mfcc, self.label_to_index[label]\n",
    "\n",
    "train_dataset = SpeechCommandsDataset('training')\n",
    "val_dataset = SpeechCommandsDataset('validation')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# ------------------------\n",
    "# Poisson Spike Generator\n",
    "# ------------------------\n",
    "\n",
    "class PoissonSpikeGen:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, data, time_steps):\n",
    "        # data: (batch, features, time)\n",
    "        batch_size, feature_dim, time_dim = data.shape\n",
    "        data = data.unsqueeze(1).repeat(1, time_steps, 1, 1)  # (batch, time, feature, time)\n",
    "        spikes = torch.rand_like(data) < data\n",
    "        return spikes.float()\n",
    "\n",
    "poisson_gen = PoissonSpikeGen()\n",
    "\n",
    "# ------------------------\n",
    "# Simple SNN Model\n",
    "# ------------------------\n",
    "\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self, num_classes=35):\n",
    "        super(SNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 5 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "        self.threshold = 1.0\n",
    "        self.decay = 0.25\n",
    "\n",
    "    def forward(self, x, time_steps=20):\n",
    "        mem1 = mem2 = mem3 = mem4 = 0\n",
    "        spk1 = spk2 = spk3 = spk4 = 0\n",
    "\n",
    "        total_spikes = 0\n",
    "\n",
    "        for t in range(time_steps):\n",
    "            inp = x[:, t, None, :, :]\n",
    "\n",
    "            cur1 = self.conv1(inp)\n",
    "            mem1 = mem1 * self.decay + cur1\n",
    "            spk1 = (mem1 >= self.threshold).float()\n",
    "            mem1 = mem1 * (1 - spk1)\n",
    "\n",
    "            cur2 = self.conv2(spk1)\n",
    "            mem2 = mem2 * self.decay + cur2\n",
    "            spk2 = (mem2 >= self.threshold).float()\n",
    "            mem2 = mem2 * (1 - spk2)\n",
    "\n",
    "            spk2_flat = spk2.view(spk2.size(0), -1)\n",
    "            cur3 = self.fc1(spk2_flat)\n",
    "            mem3 = mem3 * self.decay + cur3\n",
    "            spk3 = (mem3 >= self.threshold).float()\n",
    "            mem3 = mem3 * (1 - spk3)\n",
    "\n",
    "            cur4 = self.fc2(spk3)\n",
    "            mem4 = mem4 * self.decay + cur4\n",
    "            spk4 = (mem4 >= self.threshold).float()\n",
    "            mem4 = mem4 * (1 - spk4)\n",
    "\n",
    "            total_spikes += spk4.sum()\n",
    "\n",
    "        out = mem4 / time_steps\n",
    "        return out, total_spikes\n",
    "\n",
    "net = SNN(num_classes=len(train_dataset.labels)).to(device)\n",
    "\n",
    "# ------------------------\n",
    "# Training Loop\n",
    "# ------------------------\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 20\n",
    "time_steps = 20\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    net.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_spikes = 0\n",
    "\n",
    "    for data, targets in train_loader:\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        spike_input = poisson_gen(data, time_steps).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs, spikes = net(spike_input, time_steps)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = outputs.argmax(1)\n",
    "        correct += (preds == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "        total_spikes += spikes.item()\n",
    "\n",
    "    train_acc = correct / total\n",
    "    train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in val_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            spike_input = poisson_gen(data, time_steps).to(device)\n",
    "            outputs, _ = net(spike_input, time_steps)\n",
    "            preds = outputs.argmax(1)\n",
    "            correct += (preds == targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "\n",
    "    val_acc = correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch}, Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}, Validation Accuracy: {val_acc:.4f}, Total Spikes: {int(total_spikes)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [1313] at entry 0 and [819] at entry 28",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 134\u001b[0m\n\u001b[0;32m    131\u001b[0m total_possible \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# Training pass\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:144\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtransposed\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:144\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:121\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:174\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    172\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    173\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1313] at entry 0 and [819] at entry 28"
     ]
    }
   ],
   "source": [
    "# Spiking Neural Network for Google Speech Commands using MFCC and Poisson encoding\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchaudio\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define target classes (10 commands)\n",
    "classes = [\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"]\n",
    "\n",
    "# Subclass to load SpeechCommands dataset splits (train/validation/test)\n",
    "class SubsetSC(torchaudio.datasets.SPEECHCOMMANDS):\n",
    "    def __init__(self, subset: str = None):\n",
    "        super().__init__(\"./\", download=True)\n",
    "        def load_list(filename):\n",
    "            filepath = os.path.join(self._path, filename)\n",
    "            with open(filepath) as fileobj:\n",
    "                return [os.path.normpath(os.path.join(self._path, line.strip())) for line in fileobj]\n",
    "        if subset == \"validation\":\n",
    "            self._walker = load_list(\"validation_list.txt\")\n",
    "        elif subset == \"testing\":\n",
    "            self._walker = load_list(\"testing_list.txt\")\n",
    "        elif subset == \"training\":\n",
    "            excludes = load_list(\"validation_list.txt\") + load_list(\"testing_list.txt\")\n",
    "            excludes = set(excludes)\n",
    "            self._walker = [w for w in self._walker if w not in excludes]\n",
    "\n",
    "# Dataset to compute MFCC and filter to the 10 classes\n",
    "class SpeechCommandsMFCC(Dataset):\n",
    "    def __init__(self, subset, classes, mfcc_transform):\n",
    "        self.dataset = SubsetSC(subset)\n",
    "        self.classes = classes\n",
    "        self.mfcc_transform = mfcc_transform\n",
    "        # Filter indices to include only target classes\n",
    "        self.indices = [i for i in range(len(self.dataset)) if self.dataset[i][2] in classes]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load waveform and label\n",
    "        waveform, sample_rate, label, *_ = self.dataset[self.indices[idx]]\n",
    "        # Compute MFCC features (shape: [1, n_mfcc, time_frames])\n",
    "        mfcc = self.mfcc_transform(waveform).squeeze(0)  # remove channel dimension\n",
    "        # Normalize MFCC values to [0,1] per sample for Poisson rate coding\n",
    "        mfcc = mfcc - mfcc.min()\n",
    "        if mfcc.max() != 0:\n",
    "            mfcc = mfcc / mfcc.max()\n",
    "        # Flatten MFCC features into a 1D vector\n",
    "        x = mfcc.flatten()\n",
    "        # Convert label to class index\n",
    "        y = self.classes.index(label)\n",
    "        return x, y\n",
    "\n",
    "# Define MFCC transform: 13 coefficients\n",
    "mfcc_transform = torchaudio.transforms.MFCC(\n",
    "    sample_rate=16000,\n",
    "    n_mfcc=13,\n",
    "    melkwargs={\"n_fft\": 400, \"hop_length\": 160, \"n_mels\": 40}\n",
    ")\n",
    "\n",
    "# Create training and validation datasets and loaders\n",
    "train_dataset = SpeechCommandsMFCC(subset=\"training\", classes=classes, mfcc_transform=mfcc_transform)\n",
    "val_dataset   = SpeechCommandsMFCC(subset=\"testing\",  classes=classes, mfcc_transform=mfcc_transform)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Determine input dimension (flattened MFCC length)\n",
    "input_dim  = train_dataset[0][0].shape[0]\n",
    "hidden_dim = 100\n",
    "output_dim = len(classes)\n",
    "\n",
    "# Define the Spiking Neural Network model with two fully-connected LIF layers\n",
    "class SpikingNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SpikingNN, self).__init__()\n",
    "        # First fully connected layer\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        # LIF neuron after first layer\n",
    "        self.lif1 = snn.Leaky(beta=0.9, spike_grad=surrogate.fast_sigmoid())\n",
    "        # Second fully connected layer\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        # LIF neuron after second layer\n",
    "        self.lif2 = snn.Leaky(beta=0.9, spike_grad=surrogate.fast_sigmoid())\n",
    "\n",
    "    def forward(self, x, num_steps=25):\n",
    "        # x shape: [batch, input_dim], with values in [0,1] for Poisson encoding\n",
    "        mem1 = None  # membrane potential for first layer\n",
    "        mem2 = None  # membrane potential for second layer\n",
    "        # Accumulate output spikes over time steps\n",
    "        spk2_sum = torch.zeros(x.size(0), self.fc2.out_features, device=x.device)\n",
    "        for t in range(num_steps):\n",
    "            # Generate Poisson spikes for input\n",
    "            input_spikes = torch.bernoulli(x)\n",
    "            # Forward through first layer and LIF neuron\n",
    "            cur1 = self.fc1(input_spikes)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            # Forward through second layer and LIF neuron\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            # Accumulate output spikes for classification\n",
    "            spk2_sum += spk2\n",
    "        return spk2_sum\n",
    "\n",
    "# Instantiate model, loss function, and optimizer\n",
    "model = SpikingNN(input_dim, hidden_dim, output_dim).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training settings\n",
    "num_epochs = 10\n",
    "num_steps  = 25  # time steps\n",
    "\n",
    "# Training and validation loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss   = 0.0\n",
    "    correct_train  = 0\n",
    "    total_train    = 0\n",
    "    total_spikes   = 0.0\n",
    "    total_possible = 0.0\n",
    "\n",
    "    # Training pass\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs, num_steps=num_steps)     # Forward pass (spiking)\n",
    "        loss = criterion(outputs, labels)                # Compute loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update training metrics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        total_train   += labels.size(0)\n",
    "        # Count spikes in output layer\n",
    "        total_spikes   += outputs.sum().item()\n",
    "        total_possible += num_steps * inputs.size(0) * output_dim\n",
    "\n",
    "    epoch_loss = running_loss / total_train\n",
    "    train_acc  = 100.0 * correct_train / total_train\n",
    "    spike_rate = total_spikes / total_possible\n",
    "\n",
    "    # Validation pass\n",
    "    model.eval()\n",
    "    correct_val = 0\n",
    "    total_val   = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs, num_steps=num_steps)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "            total_val   += labels.size(0)\n",
    "    val_acc = 100.0 * correct_val / total_val\n",
    "\n",
    "    # Print metrics for this epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "          f\"Loss: {epoch_loss:.4f}, \"\n",
    "          f\"Train Acc: {train_acc:.2f}%, \"\n",
    "          f\"Val Acc: {val_acc:.2f}%, \"\n",
    "          f\"Spike Rate: {spike_rate:.4f}, \"\n",
    "          f\"Total Spikes: {total_spikes:.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.26G/2.26G [08:52<00:00, 4.56MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.3026, Spike Rate: 0.0850, Train Accuracy: 0.1406, Validation Accuracy: 0.1072\n",
      "Epoch 2, Loss: 2.3026, Spike Rate: 0.0900, Train Accuracy: 0.0625, Validation Accuracy: 0.1072\n",
      "Epoch 3, Loss: 2.3026, Spike Rate: 0.1000, Train Accuracy: 0.1094, Validation Accuracy: 0.1072\n",
      "Epoch 4, Loss: 2.3026, Spike Rate: 0.1038, Train Accuracy: 0.0938, Validation Accuracy: 0.1072\n",
      "Epoch 5, Loss: 2.3026, Spike Rate: 0.1000, Train Accuracy: 0.0625, Validation Accuracy: 0.1072\n",
      "Epoch 6, Loss: 2.3026, Spike Rate: 0.1050, Train Accuracy: 0.2188, Validation Accuracy: 0.1072\n",
      "Epoch 7, Loss: 2.3026, Spike Rate: 0.1100, Train Accuracy: 0.0938, Validation Accuracy: 0.1072\n",
      "Epoch 8, Loss: 2.3026, Spike Rate: 0.1350, Train Accuracy: 0.1094, Validation Accuracy: 0.1072\n",
      "Epoch 9, Loss: 2.3026, Spike Rate: 0.1400, Train Accuracy: 0.1406, Validation Accuracy: 0.1072\n",
      "Epoch 10, Loss: 2.3026, Spike Rate: 0.1500, Train Accuracy: 0.0781, Validation Accuracy: 0.1072\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# snn_speech_baseline.py\n",
    "# Baseline SNN for Google Speech Commands classification using snntorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import snntorch as snn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from snntorch import surrogate\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "num_steps = 25\n",
    "num_inputs = 13 * 100  # 13 MFCC coefficients x 100 frames\n",
    "num_hidden = 100\n",
    "num_outputs = 10  # Number of target words\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 10\n",
    "max_frames = 100  # MFCC time-steps (padded/cropped to 100)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Classes to recognize\n",
    "target_classes = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
    "\n",
    "# Define dataset\n",
    "class SubsetSC(torchaudio.datasets.SPEECHCOMMANDS):\n",
    "    def __init__(self, subset: str = None):\n",
    "        super().__init__(root=\"./data\", download=True)\n",
    "        if subset == \"validation\":\n",
    "            self._walker = self._load_list(\"validation_list.txt\")\n",
    "        elif subset == \"testing\":\n",
    "            self._walker = self._load_list(\"testing_list.txt\")\n",
    "        elif subset == \"training\":\n",
    "            excludes = set(self._load_list(\"validation_list.txt\") + self._load_list(\"testing_list.txt\"))\n",
    "            self._walker = [w for w in self._walker if w not in excludes]\n",
    "\n",
    "    def _load_list(self, filename):\n",
    "        filepath = os.path.join(self._path, filename)\n",
    "        with open(filepath) as f:\n",
    "            return [os.path.join(self._path, line.strip()) for line in f]\n",
    "\n",
    "# MFCC transform\n",
    "mfcc_transform = torchaudio.transforms.MFCC(\n",
    "    sample_rate=16000,\n",
    "    n_mfcc=13,\n",
    "    melkwargs={\"n_fft\": 400, \"hop_length\": 160, \"n_mels\": 40}\n",
    ")\n",
    "\n",
    "# Speech dataset class\n",
    "class SpeechCommandsMFCC(Dataset):\n",
    "    def __init__(self, subset, classes, mfcc_transform, max_frames=100):\n",
    "        self.dataset = SubsetSC(subset)\n",
    "        self.classes = classes\n",
    "        self.mfcc_transform = mfcc_transform\n",
    "        self.max_frames = max_frames\n",
    "        self.indices = [i for i in range(len(self.dataset)) if self.dataset[i][2] in classes]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        waveform, sample_rate, label, *_ = self.dataset[self.indices[idx]]\n",
    "        mfcc = self.mfcc_transform(waveform).squeeze(0)  # shape (n_mfcc, time)\n",
    "\n",
    "        # Normalize MFCC\n",
    "        mfcc = mfcc - mfcc.min()\n",
    "        if mfcc.max() != 0:\n",
    "            mfcc = mfcc / mfcc.max()\n",
    "\n",
    "        # Pad or crop\n",
    "        n_mfcc, time_steps = mfcc.shape\n",
    "        if time_steps < self.max_frames:\n",
    "            pad_size = self.max_frames - time_steps\n",
    "            mfcc = F.pad(mfcc, (0, pad_size))\n",
    "        else:\n",
    "            mfcc = mfcc[:, :self.max_frames]\n",
    "\n",
    "        x = mfcc.flatten()\n",
    "        y = self.classes.index(label)\n",
    "        return x, y\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = SpeechCommandsMFCC('training', target_classes, mfcc_transform, max_frames)\n",
    "val_dataset = SpeechCommandsMFCC('validation', target_classes, mfcc_transform, max_frames)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "# Surrogate gradient\n",
    "spike_grad = surrogate.fast_sigmoid(slope=25)\n",
    "\n",
    "# SNN model\n",
    "class BaselineSNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lif1 = snn.Leaky(beta=0.9, spike_grad=spike_grad)\n",
    "        self.lif2 = snn.Leaky(beta=0.9, spike_grad=spike_grad)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(1)\n",
    "        mem1, mem2 = self.lif1.init_leaky(), self.lif2.init_leaky()\n",
    "        spk1_rec, spk2_rec = [], []\n",
    "        for step in range(num_steps):\n",
    "            cur1 = self.fc1(x[step])\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk1_rec.append(spk1)\n",
    "            spk2_rec.append(spk2)\n",
    "        return torch.stack(spk1_rec, dim=0), torch.stack(spk2_rec, dim=0)\n",
    "\n",
    "# Instantiate model\n",
    "net = BaselineSNN().to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training\n",
    "accuracies, val_accuracies, spike_rates, losses = [], [], [], []\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size_actual = inputs.size(0)\n",
    "\n",
    "        # Normalize\n",
    "        if inputs.max() > 0:\n",
    "            inputs = inputs / inputs.max()\n",
    "\n",
    "        # Generate spike train input\n",
    "        spike_inputs = (torch.rand(num_steps, batch_size_actual, num_inputs, device=device) < inputs.unsqueeze(0) * 0.3).float()\n",
    "\n",
    "        spk1_rec, outputs = net(spike_inputs)\n",
    "        spk_count = outputs.sum(dim=0)\n",
    "\n",
    "        loss = criterion(spk_count, labels)\n",
    "        spike_rate = (spk1_rec.mean() + outputs.mean()) / 2\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        correct = (spk_count.argmax(dim=1) == labels).sum().item()\n",
    "        accuracy = correct / batch_size_actual\n",
    "\n",
    "    scheduler.step()\n",
    "    losses.append(loss.item())\n",
    "    spike_rates.append(spike_rate.item())\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    # Validation\n",
    "    net.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            batch_size_actual = inputs.size(0)\n",
    "\n",
    "            if inputs.max() > 0:\n",
    "                inputs = inputs / inputs.max()\n",
    "\n",
    "            spike_inputs = (torch.rand(num_steps, batch_size_actual, num_inputs, device=device) < inputs.unsqueeze(0) * 0.3).float()\n",
    "\n",
    "            spk1_rec, outputs = net(spike_inputs)\n",
    "            spk_count = outputs.sum(dim=0)\n",
    "\n",
    "            total_correct += (spk_count.argmax(dim=1) == labels).sum().item()\n",
    "            total_samples += batch_size_actual\n",
    "\n",
    "    val_accuracy = total_correct / total_samples\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}, Spike Rate: {spike_rate.item():.4f}, Train Accuracy: {accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(accuracies, label=\"Train Accuracy\")\n",
    "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(spike_rates, label=\"Spike Rate\")\n",
    "plt.title(\"Spike Rate\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(losses, label=\"Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"speech_baseline_results.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [20, 101] at entry 0 and [20, 99] at entry 6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 112\u001b[0m\n\u001b[0;32m    109\u001b[0m net\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    110\u001b[0m running_loss, correct, total_spikes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 112\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:144\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtransposed\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:144\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:121\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:174\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    172\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    173\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [20, 101] at entry 0 and [20, 99] at entry 6"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import random\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load Dataset\n",
    "data_path = './'\n",
    "train_dataset = torchaudio.datasets.SPEECHCOMMANDS(root=data_path, download=True, subset='training')\n",
    "val_dataset = torchaudio.datasets.SPEECHCOMMANDS(root=data_path, download=True, subset='validation')\n",
    "\n",
    "target_classes = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
    "class_to_idx = {label: idx for idx, label in enumerate(target_classes)}\n",
    "\n",
    "def preprocess(waveform, sample_rate):\n",
    "    transform = torchaudio.transforms.MFCC(\n",
    "        sample_rate=sample_rate,\n",
    "        n_mfcc=20,\n",
    "        melkwargs={'n_fft': 400, 'hop_length': 160, 'n_mels': 64}\n",
    "    )\n",
    "    mfcc = transform(waveform)\n",
    "    mfcc = mfcc.squeeze(0)\n",
    "    return mfcc\n",
    "\n",
    "class SubsetSC(torch.utils.data.Dataset):\n",
    "    def __init__(self, subset):\n",
    "        self.subset = subset\n",
    "        self.samples = [(waveform, sample_rate, label) for waveform, sample_rate, label, *_ in subset if label in target_classes]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        waveform, sample_rate, label = self.samples[index]\n",
    "        mfcc = preprocess(waveform, sample_rate)\n",
    "        return mfcc, class_to_idx[label]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "train_dataset = SubsetSC(train_dataset)\n",
    "val_dataset = SubsetSC(val_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, drop_last=False)\n",
    "\n",
    "# SNN Model\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.lif1 = LIFNeuron()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.lif2 = LIFNeuron()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, steps, features = x.shape\n",
    "        spk2_rec = []\n",
    "        mem1 = self.lif1.init_mem(batch_size, self.fc1.out_features, x.device)\n",
    "        mem2 = self.lif2.init_mem(batch_size, self.fc2.out_features, x.device)\n",
    "\n",
    "        for step in range(steps):\n",
    "            cur1 = self.fc1(x[:, step, :])\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk2_rec.append(spk2)\n",
    "\n",
    "        return torch.stack(spk2_rec)\n",
    "\n",
    "class LIFNeuron(nn.Module):\n",
    "    def __init__(self, tau=2.0):\n",
    "        super().__init__()\n",
    "        self.tau = tau\n",
    "\n",
    "    def forward(self, x, mem):\n",
    "        mem = mem * self.tau + x\n",
    "        spk = (mem >= 1.0).float()\n",
    "        mem = mem * (1.0 - spk)\n",
    "        return spk, mem\n",
    "\n",
    "    def init_mem(self, batch_size, features, device):\n",
    "        return torch.zeros(batch_size, features, device=device)\n",
    "\n",
    "# Poisson Encoder\n",
    "def poisson_encode(x, num_steps):\n",
    "    shape = (num_steps,) + x.shape\n",
    "    return (torch.rand(shape, device=x.device) < x.unsqueeze(0)).float()\n",
    "\n",
    "# Training Config\n",
    "input_size = 20 * 81\n",
    "hidden_size = 256\n",
    "output_size = 10\n",
    "num_epochs = 10\n",
    "num_steps = 20\n",
    "\n",
    "net = SNN(input_size, hidden_size, output_size).to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    running_loss, correct, total_spikes = 0, 0, 0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        inputs = inputs / inputs.max()\n",
    "        inputs = inputs.view(inputs.size(0), inputs.size(2), inputs.size(1))\n",
    "\n",
    "        spk_in = poisson_encode(inputs, num_steps)\n",
    "        spk2_rec = net(spk_in)\n",
    "        spk_count = spk2_rec.sum(0)\n",
    "\n",
    "        loss = criterion(spk_count, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        correct += (spk_count.argmax(1) == targets).sum().item()\n",
    "        total_spikes += spk2_rec.sum().item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    train_acc = correct / len(train_loader.dataset)\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    avg_spike_rate = total_spikes / (len(train_loader.dataset) * num_steps * hidden_size)\n",
    "\n",
    "    # Validation\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            inputs = inputs / inputs.max()\n",
    "            inputs = inputs.view(inputs.size(0), inputs.size(2), inputs.size(1))\n",
    "\n",
    "            spk_in = poisson_encode(inputs, num_steps)\n",
    "            spk2_rec = net(spk_in)\n",
    "            spk_count = spk2_rec.sum(0)\n",
    "\n",
    "            correct += (spk_count.argmax(1) == targets).sum().item()\n",
    "\n",
    "    val_acc = correct / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}, Spike Rate: {avg_spike_rate:.4f}, Accuracy: {train_acc:.4f}, Validation Accuracy: {val_acc:.4f}, Total Spikes: {total_spikes:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 128\u001b[0m\n\u001b[0;32m    125\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mview(inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m), inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    127\u001b[0m spk_in \u001b[38;5;241m=\u001b[39m poisson_encode(inputs, num_steps)\n\u001b[1;32m--> 128\u001b[0m spk2_rec \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspk_in\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m spk_count \u001b[38;5;241m=\u001b[39m spk2_rec\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    131\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(spk_count, targets)\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[21], line 72\u001b[0m, in \u001b[0;36mSNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 72\u001b[0m     batch_size, steps, features \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     73\u001b[0m     spk2_rec \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     74\u001b[0m     mem1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlif1\u001b[38;5;241m.\u001b[39minit_mem(batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1\u001b[38;5;241m.\u001b[39mout_features, x\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load Dataset\n",
    "data_path = './'\n",
    "train_dataset = torchaudio.datasets.SPEECHCOMMANDS(root=data_path, download=True, subset='training')\n",
    "val_dataset = torchaudio.datasets.SPEECHCOMMANDS(root=data_path, download=True, subset='validation')\n",
    "\n",
    "target_classes = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
    "class_to_idx = {label: idx for idx, label in enumerate(target_classes)}\n",
    "\n",
    "# Constants\n",
    "FIXED_MFCC_LENGTH = 100  # 🔥 Fix MFCC to this many frames always\n",
    "\n",
    "def preprocess(waveform, sample_rate):\n",
    "    transform = torchaudio.transforms.MFCC(\n",
    "        sample_rate=sample_rate,\n",
    "        n_mfcc=20,\n",
    "        melkwargs={'n_fft': 400, 'hop_length': 160, 'n_mels': 64}\n",
    "    )\n",
    "    mfcc = transform(waveform).squeeze(0)  # [20, Time]\n",
    "    time_steps = mfcc.shape[1]\n",
    "\n",
    "    if time_steps < FIXED_MFCC_LENGTH:\n",
    "        pad_amt = FIXED_MFCC_LENGTH - time_steps\n",
    "        mfcc = F.pad(mfcc, (0, pad_amt))\n",
    "    else:\n",
    "        mfcc = mfcc[:, :FIXED_MFCC_LENGTH]\n",
    "\n",
    "    return mfcc\n",
    "\n",
    "class SubsetSC(torch.utils.data.Dataset):\n",
    "    def __init__(self, subset):\n",
    "        self.subset = subset\n",
    "        self.samples = [(waveform, sample_rate, label) for waveform, sample_rate, label, *_ in subset if label in target_classes]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        waveform, sample_rate, label = self.samples[index]\n",
    "        mfcc = preprocess(waveform, sample_rate)\n",
    "        return mfcc, class_to_idx[label]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "train_dataset = SubsetSC(train_dataset)\n",
    "val_dataset = SubsetSC(val_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, drop_last=False)\n",
    "\n",
    "# SNN Model\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.lif1 = LIFNeuron()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.lif2 = LIFNeuron()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, steps, features = x.shape\n",
    "        spk2_rec = []\n",
    "        mem1 = self.lif1.init_mem(batch_size, self.fc1.out_features, x.device)\n",
    "        mem2 = self.lif2.init_mem(batch_size, self.fc2.out_features, x.device)\n",
    "\n",
    "        for step in range(steps):\n",
    "            cur1 = self.fc1(x[:, step, :])\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk2_rec.append(spk2)\n",
    "\n",
    "        return torch.stack(spk2_rec)\n",
    "\n",
    "class LIFNeuron(nn.Module):\n",
    "    def __init__(self, tau=2.0):\n",
    "        super().__init__()\n",
    "        self.tau = tau\n",
    "\n",
    "    def forward(self, x, mem):\n",
    "        mem = mem * self.tau + x\n",
    "        spk = (mem >= 1.0).float()\n",
    "        mem = mem * (1.0 - spk)\n",
    "        return spk, mem\n",
    "\n",
    "    def init_mem(self, batch_size, features, device):\n",
    "        return torch.zeros(batch_size, features, device=device)\n",
    "\n",
    "# Poisson Encoder\n",
    "def poisson_encode(x, num_steps):\n",
    "    shape = (num_steps,) + x.shape\n",
    "    return (torch.rand(shape, device=x.device) < x.unsqueeze(0)).float()\n",
    "\n",
    "# Training Config\n",
    "input_size = 20 * FIXED_MFCC_LENGTH\n",
    "hidden_size = 256\n",
    "output_size = 10\n",
    "num_epochs = 10\n",
    "num_steps = 20\n",
    "\n",
    "net = SNN(input_size, hidden_size, output_size).to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    running_loss, correct, total_spikes = 0, 0, 0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        inputs = inputs / inputs.max()\n",
    "        inputs = inputs.view(inputs.size(0), inputs.size(2), inputs.size(1))\n",
    "\n",
    "        spk_in = poisson_encode(inputs, num_steps)\n",
    "        spk2_rec = net(spk_in)\n",
    "        spk_count = spk2_rec.sum(0)\n",
    "\n",
    "        loss = criterion(spk_count, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        correct += (spk_count.argmax(1) == targets).sum().item()\n",
    "        total_spikes += spk2_rec.sum().item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    train_acc = correct / len(train_loader.dataset)\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    avg_spike_rate = total_spikes / (len(train_loader.dataset) * num_steps * hidden_size)\n",
    "\n",
    "    # Validation\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            inputs = inputs / inputs.max()\n",
    "            inputs = inputs.view(inputs.size(0), inputs.size(2), inputs.size(1))\n",
    "\n",
    "            spk_in = poisson_encode(inputs, num_steps)\n",
    "            spk2_rec = net(spk_in)\n",
    "            spk_count = spk2_rec.sum(0)\n",
    "\n",
    "            correct += (spk_count.argmax(1) == targets).sum().item()\n",
    "\n",
    "    val_acc = correct / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}, Spike Rate: {avg_spike_rate:.4f}, Accuracy: {train_acc:.4f}, Validation Accuracy: {val_acc:.4f}, Total Spikes: {total_spikes:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.26G/2.26G [10:43<00:00, 3.78MB/s] \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: \"d:\\\\Snn's\\\\speechcommands_data\\\\training_list.txt\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 68\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path, line\u001b[38;5;241m.\u001b[39mstrip())) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f]\n\u001b[1;32m---> 68\u001b[0m train_list \u001b[38;5;241m=\u001b[39m \u001b[43mload_list\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_list.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m val_list \u001b[38;5;241m=\u001b[39m load_list(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_list.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Filter samples\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[22], line 65\u001b[0m, in \u001b[0;36mload_list\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_list\u001b[39m(filename):\n\u001b[0;32m     64\u001b[0m     filepath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path, filename)\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path, line\u001b[38;5;241m.\u001b[39mstrip())) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f]\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: \"d:\\\\Snn's\\\\speechcommands_data\\\\training_list.txt\""
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm  # Progress bar\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data Path\n",
    "data_path = os.path.join(os.getcwd(), \"speechcommands_data\")\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "# Target Classes\n",
    "target_classes = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
    "class_to_idx = {label: idx for idx, label in enumerate(target_classes)}\n",
    "\n",
    "# Constants\n",
    "FIXED_MFCC_LENGTH = 100  # 🔥 Fix MFCC to this many frames always\n",
    "\n",
    "# Preprocessing MFCC\n",
    "def preprocess(waveform, sample_rate):\n",
    "    transform = torchaudio.transforms.MFCC(\n",
    "        sample_rate=sample_rate,\n",
    "        n_mfcc=20,\n",
    "        melkwargs={'n_fft': 400, 'hop_length': 160, 'n_mels': 64}\n",
    "    )\n",
    "    mfcc = transform(waveform).squeeze(0)  # [20, Time]\n",
    "    time_steps = mfcc.shape[1]\n",
    "\n",
    "    if time_steps < FIXED_MFCC_LENGTH:\n",
    "        pad_amt = FIXED_MFCC_LENGTH - time_steps\n",
    "        mfcc = F.pad(mfcc, (0, pad_amt))\n",
    "    else:\n",
    "        mfcc = mfcc[:, :FIXED_MFCC_LENGTH]\n",
    "\n",
    "    return mfcc\n",
    "\n",
    "# Subset SpeechCommands\n",
    "class SubsetSC(torch.utils.data.Dataset):\n",
    "    def __init__(self, samples):\n",
    "        self.samples = samples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        waveform, sample_rate, label, *_ = self.samples[index]\n",
    "        mfcc = preprocess(waveform, sample_rate)\n",
    "        return mfcc, class_to_idx[label]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "# Load complete dataset\n",
    "full_dataset = torchaudio.datasets.SPEECHCOMMANDS(root=data_path, download=True)\n",
    "\n",
    "# Load official splits\n",
    "def load_list(filename):\n",
    "    filepath = os.path.join(data_path, filename)\n",
    "    with open(filepath) as f:\n",
    "        return [os.path.normpath(os.path.join(data_path, line.strip())) for line in f]\n",
    "\n",
    "train_list = load_list(\"training_list.txt\")\n",
    "val_list = load_list(\"validation_list.txt\")\n",
    "\n",
    "# Filter samples\n",
    "train_samples = [sample for sample in full_dataset if sample[3] in train_list and sample[2] in target_classes]\n",
    "val_samples = [sample for sample in full_dataset if sample[3] in val_list and sample[2] in target_classes]\n",
    "\n",
    "# Create dataset objects\n",
    "train_dataset = SubsetSC(train_samples)\n",
    "val_dataset = SubsetSC(val_samples)\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, drop_last=False)\n",
    "\n",
    "# Leaky Integrate and Fire Neuron\n",
    "class LIFNeuron(nn.Module):\n",
    "    def __init__(self, tau=2.0):\n",
    "        super().__init__()\n",
    "        self.tau = tau\n",
    "\n",
    "    def forward(self, x, mem):\n",
    "        mem = mem * self.tau + x\n",
    "        spk = (mem >= 1.0).float()\n",
    "        mem = mem * (1.0 - spk)\n",
    "        return spk, mem\n",
    "\n",
    "    def init_mem(self, batch_size, features, device):\n",
    "        return torch.zeros(batch_size, features, device=device)\n",
    "\n",
    "# SNN Model\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.lif1 = LIFNeuron()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.lif2 = LIFNeuron()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, steps, features = x.shape\n",
    "        spk2_rec = []\n",
    "        mem1 = self.lif1.init_mem(batch_size, self.fc1.out_features, x.device)\n",
    "        mem2 = self.lif2.init_mem(batch_size, self.fc2.out_features, x.device)\n",
    "\n",
    "        for step in range(steps):\n",
    "            cur1 = self.fc1(x[:, step, :])\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk2_rec.append(spk2)\n",
    "\n",
    "        return torch.stack(spk2_rec)\n",
    "\n",
    "# Poisson Encoder\n",
    "def poisson_encode(x, num_steps):\n",
    "    shape = (num_steps,) + x.shape\n",
    "    return (torch.rand(shape, device=x.device) < x.unsqueeze(0)).float()\n",
    "\n",
    "# Training Config\n",
    "input_size = 20 * FIXED_MFCC_LENGTH\n",
    "hidden_size = 256\n",
    "output_size = 10\n",
    "num_epochs = 10\n",
    "num_steps = 20\n",
    "\n",
    "net = SNN(input_size, hidden_size, output_size).to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    running_loss, correct, total_spikes = 0, 0, 0\n",
    "\n",
    "    train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Training]\", leave=False)\n",
    "\n",
    "    for inputs, targets in train_loader_tqdm:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        inputs = inputs / inputs.max()\n",
    "        inputs = inputs.view(inputs.size(0), inputs.size(2), inputs.size(1))\n",
    "\n",
    "        spk_in = poisson_encode(inputs, num_steps)\n",
    "        spk2_rec = net(spk_in)\n",
    "        spk_count = spk2_rec.sum(0)\n",
    "\n",
    "        loss = criterion(spk_count, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        correct += (spk_count.argmax(1) == targets).sum().item()\n",
    "        total_spikes += spk2_rec.sum().item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    train_acc = correct / len(train_loader.dataset)\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    avg_spike_rate = total_spikes / (len(train_loader.dataset) * num_steps * hidden_size)\n",
    "\n",
    "    # Validation\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        val_loader_tqdm = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Validation]\", leave=False)\n",
    "\n",
    "        for inputs, targets in val_loader_tqdm:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            inputs = inputs / inputs.max()\n",
    "            inputs = inputs.view(inputs.size(0), inputs.size(2), inputs.size(1))\n",
    "\n",
    "            spk_in = poisson_encode(inputs, num_steps)\n",
    "            spk2_rec = net(spk_in)\n",
    "            spk_count = spk2_rec.sum(0)\n",
    "\n",
    "            correct += (spk_count.argmax(1) == targets).sum().item()\n",
    "\n",
    "    val_acc = correct / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}, Spike Rate: {avg_spike_rate:.4f}, \"\n",
    "          f\"Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Total Spikes: {total_spikes:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 130\u001b[0m\n\u001b[0;32m    127\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mview(inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m), inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# [Batch, Steps, Features]\u001b[39;00m\n\u001b[0;32m    129\u001b[0m spk_in \u001b[38;5;241m=\u001b[39m poisson_encode(inputs, num_steps)\n\u001b[1;32m--> 130\u001b[0m spk2_rec \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspk_in\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m spk_count \u001b[38;5;241m=\u001b[39m spk2_rec\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    133\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(spk_count, targets)\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[25], line 74\u001b[0m, in \u001b[0;36mSNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 74\u001b[0m     batch_size, steps, features \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     75\u001b[0m     spk2_rec \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     76\u001b[0m     mem1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlif1\u001b[38;5;241m.\u001b[39minit_mem(batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1\u001b[38;5;241m.\u001b[39mout_features, x\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Constants\n",
    "data_path = './speechcommands_data'\n",
    "target_classes = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
    "class_to_idx = {label: idx for idx, label in enumerate(target_classes)}\n",
    "FIXED_MFCC_LENGTH = 100  # 🔥 Fix MFCC to this many frames always\n",
    "\n",
    "# Preprocess Function\n",
    "def preprocess(waveform, sample_rate):\n",
    "    transform = torchaudio.transforms.MFCC(\n",
    "        sample_rate=sample_rate,\n",
    "        n_mfcc=20,\n",
    "        melkwargs={'n_fft': 400, 'hop_length': 160, 'n_mels': 64}\n",
    "    )\n",
    "    mfcc = transform(waveform).squeeze(0)  # [20, Time]\n",
    "    time_steps = mfcc.shape[1]\n",
    "\n",
    "    if time_steps < FIXED_MFCC_LENGTH:\n",
    "        pad_amt = FIXED_MFCC_LENGTH - time_steps\n",
    "        mfcc = F.pad(mfcc, (0, pad_amt))\n",
    "    else:\n",
    "        mfcc = mfcc[:, :FIXED_MFCC_LENGTH]\n",
    "\n",
    "    return mfcc\n",
    "\n",
    "# Dataset Wrapper\n",
    "class SubsetSC(torch.utils.data.Dataset):\n",
    "    def __init__(self, samples):\n",
    "        self.samples = [(waveform, sample_rate, label) for waveform, sample_rate, label, *_ in samples if label in target_classes]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        waveform, sample_rate, label = self.samples[index]\n",
    "        mfcc = preprocess(waveform, sample_rate)\n",
    "        return mfcc, class_to_idx[label]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "# --- 🛠️ Dataset Loading Correctly ---\n",
    "# Use torchaudio's subset support, NO manual file reads needed\n",
    "full_train_dataset = torchaudio.datasets.SPEECHCOMMANDS(root=data_path, download=True, subset='training')\n",
    "full_val_dataset = torchaudio.datasets.SPEECHCOMMANDS(root=data_path, download=True, subset='validation')\n",
    "\n",
    "# Filter only target classes\n",
    "train_dataset = SubsetSC(full_train_dataset)\n",
    "val_dataset = SubsetSC(full_val_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, drop_last=False)\n",
    "\n",
    "# --- SNN Model ---\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.lif1 = LIFNeuron()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.lif2 = LIFNeuron()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, steps, features = x.shape\n",
    "        spk2_rec = []\n",
    "        mem1 = self.lif1.init_mem(batch_size, self.fc1.out_features, x.device)\n",
    "        mem2 = self.lif2.init_mem(batch_size, self.fc2.out_features, x.device)\n",
    "\n",
    "        for step in range(steps):\n",
    "            cur1 = self.fc1(x[:, step, :])\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk2_rec.append(spk2)\n",
    "\n",
    "        return torch.stack(spk2_rec)\n",
    "\n",
    "class LIFNeuron(nn.Module):\n",
    "    def __init__(self, tau=2.0):\n",
    "        super().__init__()\n",
    "        self.tau = tau\n",
    "\n",
    "    def forward(self, x, mem):\n",
    "        mem = mem * self.tau + x\n",
    "        spk = (mem >= 1.0).float()\n",
    "        mem = mem * (1.0 - spk)\n",
    "        return spk, mem\n",
    "\n",
    "    def init_mem(self, batch_size, features, device):\n",
    "        return torch.zeros(batch_size, features, device=device)\n",
    "\n",
    "# Poisson Encoder\n",
    "def poisson_encode(x, num_steps):\n",
    "    shape = (num_steps,) + x.shape\n",
    "    return (torch.rand(shape, device=x.device) < x.unsqueeze(0)).float()\n",
    "\n",
    "# --- Training Config ---\n",
    "input_size = 20 * FIXED_MFCC_LENGTH\n",
    "hidden_size = 256\n",
    "output_size = 10\n",
    "num_epochs = 10\n",
    "num_steps = 20\n",
    "\n",
    "net = SNN(input_size, hidden_size, output_size).to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# --- Training Loop ---\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    running_loss, correct, total_spikes = 0, 0, 0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        inputs = inputs / inputs.max()\n",
    "        inputs = inputs.view(inputs.size(0), inputs.size(2), inputs.size(1))  # [Batch, Steps, Features]\n",
    "\n",
    "        spk_in = poisson_encode(inputs, num_steps)\n",
    "        spk2_rec = net(spk_in)\n",
    "        spk_count = spk2_rec.sum(0)\n",
    "\n",
    "        loss = criterion(spk_count, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        correct += (spk_count.argmax(1) == targets).sum().item()\n",
    "        total_spikes += spk2_rec.sum().item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    train_acc = correct / len(train_loader.dataset)\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    avg_spike_rate = total_spikes / (len(train_loader.dataset) * num_steps * hidden_size)\n",
    "\n",
    "    # --- Validation ---\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            inputs = inputs / inputs.max()\n",
    "            inputs = inputs.view(inputs.size(0), inputs.size(2), inputs.size(1))\n",
    "\n",
    "            spk_in = poisson_encode(inputs, num_steps)\n",
    "            spk2_rec = net(spk_in)\n",
    "            spk_count = spk2_rec.sum(0)\n",
    "\n",
    "            correct += (spk_count.argmax(1) == targets).sum().item()\n",
    "\n",
    "    val_acc = correct / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}, Spike Rate: {avg_spike_rate:.4f}, Accuracy: {train_acc:.4f}, Validation Accuracy: {val_acc:.4f}, Total Spikes: {total_spikes:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './SpeechCommands\\\\training_list.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpeechCommands\u001b[39m\u001b[38;5;124m\"\u001b[39m, line\u001b[38;5;241m.\u001b[39mstrip())) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f]\n\u001b[1;32m---> 29\u001b[0m train_list \u001b[38;5;241m=\u001b[39m \u001b[43mload_list\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_list.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m val_list \u001b[38;5;241m=\u001b[39m load_list(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_list.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msubset_dataset\u001b[39m(dataset, file_list):\n",
      "Cell \u001b[1;32mIn[24], line 26\u001b[0m, in \u001b[0;36mload_list\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_list\u001b[39m(filename):\n\u001b[0;32m     25\u001b[0m     filepath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpeechCommands\u001b[39m\u001b[38;5;124m\"\u001b[39m, filename)\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpeechCommands\u001b[39m\u001b[38;5;124m\"\u001b[39m, line\u001b[38;5;241m.\u001b[39mstrip())) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f]\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './SpeechCommands\\\\training_list.txt'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset\n",
    "data_path = './'\n",
    "dataset = torchaudio.datasets.SPEECHCOMMANDS(root=data_path, download=True)\n",
    "\n",
    "target_classes = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
    "class_to_idx = {label: idx for idx, label in enumerate(target_classes)}\n",
    "\n",
    "# Parse dataset\n",
    "def load_list(filename):\n",
    "    filepath = os.path.join(data_path, \"SpeechCommands\", filename)\n",
    "    with open(filepath) as f:\n",
    "        return [os.path.normpath(os.path.join(data_path, \"SpeechCommands\", line.strip())) for line in f]\n",
    "\n",
    "train_list = load_list(\"training_list.txt\")\n",
    "val_list = load_list(\"validation_list.txt\")\n",
    "\n",
    "def subset_dataset(dataset, file_list):\n",
    "    files_set = set(file_list)\n",
    "    return [(waveform, sample_rate, label) for waveform, sample_rate, label, *_ in dataset \n",
    "            if label in target_classes and dataset._walker[dataset.samples.index((waveform, sample_rate, label, None))] in files_set]\n",
    "\n",
    "train_samples = subset_dataset(dataset, train_list)\n",
    "val_samples = subset_dataset(dataset, val_list)\n",
    "\n",
    "# Constants\n",
    "FIXED_MFCC_LENGTH = 100\n",
    "\n",
    "def preprocess(waveform, sample_rate):\n",
    "    transform = torchaudio.transforms.MFCC(\n",
    "        sample_rate=sample_rate,\n",
    "        n_mfcc=20,\n",
    "        melkwargs={'n_fft': 400, 'hop_length': 160, 'n_mels': 64}\n",
    "    )\n",
    "    mfcc = transform(waveform).squeeze(0).float()  # [20, Time]\n",
    "    time_steps = mfcc.shape[1]\n",
    "\n",
    "    if time_steps < FIXED_MFCC_LENGTH:\n",
    "        pad_amt = FIXED_MFCC_LENGTH - time_steps\n",
    "        mfcc = F.pad(mfcc, (0, pad_amt))\n",
    "    else:\n",
    "        mfcc = mfcc[:, :FIXED_MFCC_LENGTH]\n",
    "\n",
    "    return mfcc\n",
    "\n",
    "class SubsetSC(torch.utils.data.Dataset):\n",
    "    def __init__(self, samples):\n",
    "        self.samples = samples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        waveform, sample_rate, label = self.samples[index]\n",
    "        mfcc = preprocess(waveform, sample_rate)\n",
    "        return mfcc, class_to_idx[label]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "train_dataset = SubsetSC(train_samples)\n",
    "val_dataset = SubsetSC(val_samples)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# SNN\n",
    "class LIFNeuron(nn.Module):\n",
    "    def __init__(self, tau=2.0):\n",
    "        super().__init__()\n",
    "        self.tau = tau\n",
    "\n",
    "    def forward(self, x, mem):\n",
    "        mem = mem * self.tau + x\n",
    "        spk = (mem >= 1.0).float()\n",
    "        mem = mem * (1.0 - spk)\n",
    "        return spk, mem\n",
    "\n",
    "    def init_mem(self, batch_size, features, device):\n",
    "        return torch.zeros(batch_size, features, device=device)\n",
    "\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.lif1 = LIFNeuron()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.lif2 = LIFNeuron()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, steps, features = x.shape\n",
    "        spk2_rec = []\n",
    "        mem1 = self.lif1.init_mem(batch_size, self.fc1.out_features, x.device)\n",
    "        mem2 = self.lif2.init_mem(batch_size, self.fc2.out_features, x.device)\n",
    "\n",
    "        for step in range(steps):\n",
    "            cur1 = self.fc1(x[:, step, :])\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk2_rec.append(spk2)\n",
    "\n",
    "        return torch.stack(spk2_rec)\n",
    "\n",
    "# Poisson Encoding optimized\n",
    "def poisson_encode(x, num_steps):\n",
    "    shape = (num_steps,) + x.shape\n",
    "    return (torch.rand(shape, device=x.device) < x.unsqueeze(0)).float()\n",
    "\n",
    "# Train Config\n",
    "input_size = 20 * FIXED_MFCC_LENGTH\n",
    "hidden_size = 256\n",
    "output_size = 10\n",
    "num_epochs = 10\n",
    "num_steps = 20\n",
    "\n",
    "net = SNN(input_size, hidden_size, output_size).to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    running_loss, correct, total_spikes = 0, 0, 0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.float().to(device), targets.to(device)\n",
    "        inputs = inputs / (inputs.max(dim=2, keepdim=True)[0] + 1e-5)  # Normalization per sample\n",
    "        inputs = inputs.permute(0, 2, 1)  # [batch, steps, features]\n",
    "\n",
    "        spk_in = poisson_encode(inputs, num_steps)\n",
    "\n",
    "        spk2_rec = net(spk_in)\n",
    "        spk_count = spk2_rec.sum(0)\n",
    "\n",
    "        loss = criterion(spk_count, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        correct += (spk_count.argmax(1) == targets).sum().item()\n",
    "        total_spikes += spk2_rec.sum().item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    train_acc = correct / len(train_loader.dataset)\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    avg_spike_rate = total_spikes / (len(train_loader.dataset) * num_steps * hidden_size)\n",
    "\n",
    "    # Validation\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.float().to(device), targets.to(device)\n",
    "            inputs = inputs / (inputs.max(dim=2, keepdim=True)[0] + 1e-5)\n",
    "            inputs = inputs.permute(0, 2, 1)\n",
    "\n",
    "            spk_in = poisson_encode(inputs, num_steps)\n",
    "            spk2_rec = net(spk_in)\n",
    "            spk_count = spk2_rec.sum(0)\n",
    "\n",
    "            correct += (spk_count.argmax(1) == targets).sum().item()\n",
    "\n",
    "    val_acc = correct / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}, Spike Rate: {avg_spike_rate:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Total Spikes: {total_spikes:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 137\u001b[0m\n\u001b[0;32m    135\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(spk_count, targets)\n\u001b[0;32m    136\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 137\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(net\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m    139\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Constants\n",
    "data_path = './speechcommands_data'\n",
    "target_classes = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
    "class_to_idx = {label: idx for idx, label in enumerate(target_classes)}\n",
    "FIXED_MFCC_LENGTH = 100  # 🔥 Fix MFCC to this many frames always\n",
    "\n",
    "# Preprocess Function\n",
    "def preprocess(waveform, sample_rate):\n",
    "    transform = torchaudio.transforms.MFCC(\n",
    "        sample_rate=sample_rate,\n",
    "        n_mfcc=20,\n",
    "        melkwargs={'n_fft': 400, 'hop_length': 160, 'n_mels': 64}\n",
    "    )\n",
    "    mfcc = transform(waveform).squeeze(0)  # [20, Time]\n",
    "    time_steps = mfcc.shape[1]\n",
    "\n",
    "    if time_steps < FIXED_MFCC_LENGTH:\n",
    "        pad_amt = FIXED_MFCC_LENGTH - time_steps\n",
    "        mfcc = F.pad(mfcc, (0, pad_amt))\n",
    "    else:\n",
    "        mfcc = mfcc[:, :FIXED_MFCC_LENGTH]\n",
    "\n",
    "    return mfcc\n",
    "\n",
    "# Dataset Wrapper\n",
    "class SubsetSC(torch.utils.data.Dataset):\n",
    "    def __init__(self, samples):\n",
    "        self.samples = [(waveform, sample_rate, label) for waveform, sample_rate, label, *_ in samples if label in target_classes]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        waveform, sample_rate, label = self.samples[index]\n",
    "        mfcc = preprocess(waveform, sample_rate)\n",
    "        return mfcc, class_to_idx[label]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "# --- 🛠️ Dataset Loading Correctly ---\n",
    "full_train_dataset = torchaudio.datasets.SPEECHCOMMANDS(root=data_path, download=True, subset='training')\n",
    "full_val_dataset = torchaudio.datasets.SPEECHCOMMANDS(root=data_path, download=True, subset='validation')\n",
    "\n",
    "# Filter only target classes\n",
    "train_dataset = SubsetSC(full_train_dataset)\n",
    "val_dataset = SubsetSC(full_val_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, drop_last=False)\n",
    "\n",
    "# --- SNN Model ---\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.lif1 = LIFNeuron()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.lif2 = LIFNeuron()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, steps, features = x.shape\n",
    "        spk2_rec = []\n",
    "        mem1 = self.lif1.init_mem(batch_size, self.fc1.out_features, x.device)\n",
    "        mem2 = self.lif2.init_mem(batch_size, self.fc2.out_features, x.device)\n",
    "\n",
    "        for step in range(steps):\n",
    "            cur1 = self.fc1(x[:, step, :])\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk2_rec.append(spk2)\n",
    "\n",
    "        return torch.stack(spk2_rec)\n",
    "\n",
    "class LIFNeuron(nn.Module):\n",
    "    def __init__(self, tau=2.0):\n",
    "        super().__init__()\n",
    "        self.tau = tau\n",
    "\n",
    "    def forward(self, x, mem):\n",
    "        mem = mem * self.tau + x\n",
    "        spk = (mem >= 1.0).float()\n",
    "        mem = mem * (1.0 - spk)\n",
    "        return spk, mem\n",
    "\n",
    "    def init_mem(self, batch_size, features, device):\n",
    "        return torch.zeros(batch_size, features, device=device)\n",
    "\n",
    "# Poisson Encoder\n",
    "def poisson_encode(x, num_steps):\n",
    "    shape = (num_steps,) + x.shape\n",
    "    return (torch.rand(shape, device=x.device) < x.unsqueeze(0)).float()\n",
    "\n",
    "# --- Training Config ---\n",
    "input_size = 20 * FIXED_MFCC_LENGTH\n",
    "hidden_size = 256\n",
    "output_size = 10\n",
    "num_epochs = 10\n",
    "num_steps = 20\n",
    "\n",
    "net = SNN(input_size, hidden_size, output_size).to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# --- Training Loop ---\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    running_loss, correct, total_spikes = 0, 0, 0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        inputs = inputs / inputs.max()\n",
    "        inputs = inputs.view(inputs.size(0), inputs.size(2), inputs.size(1))  # [Batch, Steps, Features]\n",
    "\n",
    "        spk_in = poisson_encode(inputs, num_steps)\n",
    "        spk_in = spk_in.permute(1, 0, 2, 3)           # (batch_size, num_steps, steps, features)\n",
    "        spk_in = spk_in.reshape(spk_in.size(0), spk_in.size(1), -1)  # (batch_size, num_steps, steps*features)\n",
    "\n",
    "        spk2_rec = net(spk_in)\n",
    "        spk_count = spk2_rec.sum(0)\n",
    "\n",
    "        loss = criterion(spk_count, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        correct += (spk_count.argmax(1) == targets).sum().item()\n",
    "        total_spikes += spk2_rec.sum().item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    train_acc = correct / len(train_loader.dataset)\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    avg_spike_rate = total_spikes / (len(train_loader.dataset) * num_steps * hidden_size)\n",
    "\n",
    "    # --- Validation ---\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            inputs = inputs / inputs.max()\n",
    "            inputs = inputs.view(inputs.size(0), inputs.size(2), inputs.size(1))\n",
    "\n",
    "            spk_in = poisson_encode(inputs, num_steps)\n",
    "            spk_in = spk_in.permute(1, 0, 2, 3)\n",
    "            spk_in = spk_in.reshape(spk_in.size(0), spk_in.size(1), -1)\n",
    "\n",
    "            spk2_rec = net(spk_in)\n",
    "            spk_count = spk2_rec.sum(0)\n",
    "\n",
    "            correct += (spk_count.argmax(1) == targets).sum().item()\n",
    "\n",
    "    val_acc = correct / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}, Spike Rate: {avg_spike_rate:.4f}, Accuracy: {train_acc:.4f}, Validation Accuracy: {val_acc:.4f}, Total Spikes: {total_spikes:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 136\u001b[0m\n\u001b[0;32m    134\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(spk_count, targets)\n\u001b[0;32m    135\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 136\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(net\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m    138\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Constants\n",
    "data_path = './speechcommands_data'\n",
    "target_classes = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
    "class_to_idx = {label: idx for idx, label in enumerate(target_classes)}\n",
    "FIXED_MFCC_LENGTH = 100  # 🔥 Fix MFCC to this many frames always\n",
    "\n",
    "# Preprocess Function\n",
    "def preprocess(waveform, sample_rate):\n",
    "    transform = torchaudio.transforms.MFCC(\n",
    "        sample_rate=sample_rate,\n",
    "        n_mfcc=20,\n",
    "        melkwargs={'n_fft': 400, 'hop_length': 160, 'n_mels': 64}\n",
    "    )\n",
    "    mfcc = transform(waveform).squeeze(0)  # [20, Time]\n",
    "    time_steps = mfcc.shape[1]\n",
    "\n",
    "    if time_steps < FIXED_MFCC_LENGTH:\n",
    "        pad_amt = FIXED_MFCC_LENGTH - time_steps\n",
    "        mfcc = F.pad(mfcc, (0, pad_amt))\n",
    "    else:\n",
    "        mfcc = mfcc[:, :FIXED_MFCC_LENGTH]\n",
    "\n",
    "    return mfcc\n",
    "\n",
    "# Dataset Wrapper\n",
    "class SubsetSC(torch.utils.data.Dataset):\n",
    "    def __init__(self, samples):\n",
    "        self.samples = [(waveform, sample_rate, label) for waveform, sample_rate, label, *_ in samples if label in target_classes]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        waveform, sample_rate, label = self.samples[index]\n",
    "        mfcc = preprocess(waveform, sample_rate)\n",
    "        return mfcc, class_to_idx[label]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "# --- Dataset Loading ---\n",
    "full_train_dataset = torchaudio.datasets.SPEECHCOMMANDS(root=data_path, download=True, subset='training')\n",
    "full_val_dataset = torchaudio.datasets.SPEECHCOMMANDS(root=data_path, download=True, subset='validation')\n",
    "\n",
    "train_dataset = SubsetSC(full_train_dataset)\n",
    "val_dataset = SubsetSC(full_val_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, drop_last=False)\n",
    "\n",
    "# --- SNN Model ---\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.lif1 = LIFNeuron()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.lif2 = LIFNeuron()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, steps, features = x.shape\n",
    "        spk2_rec = []\n",
    "        mem1 = self.lif1.init_mem(batch_size, self.fc1.out_features, x.device)\n",
    "        mem2 = self.lif2.init_mem(batch_size, self.fc2.out_features, x.device)\n",
    "\n",
    "        for step in range(steps):\n",
    "            cur1 = self.fc1(x[:, step, :])\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk2_rec.append(spk2)\n",
    "\n",
    "        return torch.stack(spk2_rec)\n",
    "\n",
    "class LIFNeuron(nn.Module):\n",
    "    def __init__(self, tau=2.0):\n",
    "        super().__init__()\n",
    "        self.tau = tau\n",
    "\n",
    "    def forward(self, x, mem):\n",
    "        mem = mem * self.tau + x\n",
    "        spk = (mem >= 1.0).float()\n",
    "        mem = mem * (1.0 - spk)\n",
    "        return spk, mem\n",
    "\n",
    "    def init_mem(self, batch_size, features, device):\n",
    "        return torch.zeros(batch_size, features, device=device)\n",
    "\n",
    "# Poisson Encoder\n",
    "def poisson_encode(x, num_steps):\n",
    "    shape = (num_steps,) + x.shape\n",
    "    return (torch.rand(shape, device=x.device) < x.unsqueeze(0)).float()\n",
    "\n",
    "# --- Training Config ---\n",
    "input_size = 20 * FIXED_MFCC_LENGTH\n",
    "hidden_size = 256\n",
    "output_size = 10\n",
    "num_epochs = 10\n",
    "num_steps = 20\n",
    "\n",
    "net = SNN(input_size, hidden_size, output_size).to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# --- Training Loop ---\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    running_loss, correct, total_spikes = 0, 0, 0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        inputs = inputs / inputs.max()\n",
    "        inputs = inputs.view(inputs.size(0), inputs.size(2), inputs.size(1))  # [Batch, Steps, Features]\n",
    "\n",
    "        spk_in = poisson_encode(inputs, num_steps)\n",
    "        spk_in = spk_in.permute(1, 0, 2, 3)           # (num_steps, batch, steps, features)\n",
    "        spk_in = spk_in.reshape(spk_in.size(0), spk_in.size(1), -1)  # (num_steps, batch, steps*features)\n",
    "\n",
    "        spk2_rec = net(spk_in)                          # (time, batch, classes)\n",
    "        spk_count = spk2_rec.sum(0) / num_steps         # ✅ FIXED: average over steps\n",
    "\n",
    "        loss = criterion(spk_count, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        correct += (spk_count.argmax(1) == targets).sum().item()\n",
    "        total_spikes += spk2_rec.sum().item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    train_acc = correct / len(train_loader.dataset)\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    avg_spike_rate = total_spikes / (len(train_loader.dataset) * num_steps * hidden_size)\n",
    "\n",
    "    # --- Validation ---\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            inputs = inputs / inputs.max()\n",
    "            inputs = inputs.view(inputs.size(0), inputs.size(2), inputs.size(1))\n",
    "\n",
    "            spk_in = poisson_encode(inputs, num_steps)\n",
    "            spk_in = spk_in.permute(1, 0, 2, 3)\n",
    "            spk_in = spk_in.reshape(spk_in.size(0), spk_in.size(1), -1)\n",
    "\n",
    "            spk2_rec = net(spk_in)\n",
    "            spk_count = spk2_rec.sum(0) / num_steps    # ✅ SAME FIX IN VALIDATION\n",
    "\n",
    "            correct += (spk_count.argmax(1) == targets).sum().item()\n",
    "\n",
    "    val_acc = correct / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}, Spike Rate: {avg_spike_rate:.4f}, Accuracy: {train_acc:.4f}, Validation Accuracy: {val_acc:.4f}, Total Spikes: {total_spikes:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.2552, Spike Rate: 0.0006, Accuracy: 0.1058, Validation Accuracy: 0.1075, Total Spikes: 93941.3\n",
      "Epoch 2, Loss: 2.2474, Spike Rate: 0.0006, Accuracy: 0.1048, Validation Accuracy: 0.1075, Total Spikes: 92644.0\n",
      "Epoch 3, Loss: 2.2445, Spike Rate: 0.0006, Accuracy: 0.1052, Validation Accuracy: 0.1072, Total Spikes: 92492.2\n",
      "Epoch 4, Loss: 2.2424, Spike Rate: 0.0006, Accuracy: 0.1048, Validation Accuracy: 0.1072, Total Spikes: 96769.1\n",
      "Epoch 5, Loss: 2.2405, Spike Rate: 0.0006, Accuracy: 0.1048, Validation Accuracy: 0.1072, Total Spikes: 97059.4\n",
      "Epoch 6, Loss: 2.2391, Spike Rate: 0.0006, Accuracy: 0.1048, Validation Accuracy: 0.1075, Total Spikes: 88478.4\n",
      "Epoch 7, Loss: 2.2381, Spike Rate: 0.0006, Accuracy: 0.1049, Validation Accuracy: 0.1072, Total Spikes: 87547.2\n",
      "Epoch 8, Loss: 2.2371, Spike Rate: 0.0006, Accuracy: 0.1048, Validation Accuracy: 0.1072, Total Spikes: 87376.1\n",
      "Epoch 9, Loss: 2.2367, Spike Rate: 0.0005, Accuracy: 0.1049, Validation Accuracy: 0.1072, Total Spikes: 85102.3\n",
      "Epoch 10, Loss: 2.2355, Spike Rate: 0.0005, Accuracy: 0.1049, Validation Accuracy: 0.1078, Total Spikes: 84530.6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Constants\n",
    "data_path = './speechcommands_data'\n",
    "target_classes = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
    "class_to_idx = {label: idx for idx, label in enumerate(target_classes)}\n",
    "FIXED_MFCC_LENGTH = 100  # 🔥 Fix MFCC to this many frames always\n",
    "\n",
    "# Preprocess Function\n",
    "def preprocess(waveform, sample_rate):\n",
    "    transform = torchaudio.transforms.MFCC(\n",
    "        sample_rate=sample_rate,\n",
    "        n_mfcc=20,\n",
    "        melkwargs={'n_fft': 400, 'hop_length': 160, 'n_mels': 64}\n",
    "    )\n",
    "    mfcc = transform(waveform).squeeze(0)  # [20, Time]\n",
    "    time_steps = mfcc.shape[1]\n",
    "\n",
    "    if time_steps < FIXED_MFCC_LENGTH:\n",
    "        pad_amt = FIXED_MFCC_LENGTH - time_steps\n",
    "        mfcc = F.pad(mfcc, (0, pad_amt))\n",
    "    else:\n",
    "        mfcc = mfcc[:, :FIXED_MFCC_LENGTH]\n",
    "\n",
    "    return mfcc\n",
    "\n",
    "# Dataset Wrapper\n",
    "class SubsetSC(torch.utils.data.Dataset):\n",
    "    def __init__(self, samples):\n",
    "        self.samples = [(waveform, sample_rate, label) for waveform, sample_rate, label, *_ in samples if label in target_classes]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        waveform, sample_rate, label = self.samples[index]\n",
    "        mfcc = preprocess(waveform, sample_rate)\n",
    "        return mfcc, class_to_idx[label]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "# --- Dataset Loading ---\n",
    "full_train_dataset = torchaudio.datasets.SPEECHCOMMANDS(root=data_path, download=True, subset='training')\n",
    "full_val_dataset = torchaudio.datasets.SPEECHCOMMANDS(root=data_path, download=True, subset='validation')\n",
    "\n",
    "train_dataset = SubsetSC(full_train_dataset)\n",
    "val_dataset = SubsetSC(full_val_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, drop_last=False)\n",
    "\n",
    "# --- SNN Model ---\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.lif1 = LIFNeuron()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.lif2 = LIFNeuron()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, steps, features = x.shape\n",
    "        spk2_rec = []\n",
    "        mem1 = self.lif1.init_mem(batch_size, self.fc1.out_features, x.device)\n",
    "        mem2 = self.lif2.init_mem(batch_size, self.fc2.out_features, x.device)\n",
    "\n",
    "        for step in range(steps):\n",
    "            cur1 = self.fc1(x[:, step, :])\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk2_rec.append(spk2)\n",
    "\n",
    "        return torch.stack(spk2_rec)\n",
    "\n",
    "# 🔥 Corrected LIF Neuron with FastSigmoid surrogate\n",
    "class LIFNeuron(nn.Module):\n",
    "    def __init__(self, tau=2.0):\n",
    "        super().__init__()\n",
    "        self.tau = tau\n",
    "\n",
    "    def forward(self, x, mem):\n",
    "        mem = mem * self.tau + x\n",
    "        spk = self.surrogate_spike(mem - 1.0)\n",
    "        mem = mem * (1.0 - spk)\n",
    "        return spk, mem\n",
    "\n",
    "    def surrogate_spike(self, x):\n",
    "        return torch.clamp(0.5 * x + 0.5, min=0.0, max=1.0)  # 🔥 FastSigmoid\n",
    "\n",
    "    def init_mem(self, batch_size, features, device):\n",
    "        return torch.zeros(batch_size, features, device=device)\n",
    "\n",
    "# Poisson Encoder\n",
    "def poisson_encode(x, num_steps):\n",
    "    shape = (num_steps,) + x.shape\n",
    "    return (torch.rand(shape, device=x.device) < x.unsqueeze(0)).float()\n",
    "\n",
    "# --- Training Config ---\n",
    "input_size = 20 * FIXED_MFCC_LENGTH\n",
    "hidden_size = 256\n",
    "output_size = 10\n",
    "num_epochs = 10\n",
    "num_steps = 20\n",
    "\n",
    "net = SNN(input_size, hidden_size, output_size).to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# --- Training Loop ---\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    running_loss, correct, total_spikes = 0, 0, 0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        inputs = inputs / inputs.max()\n",
    "        inputs = inputs.view(inputs.size(0), inputs.size(2), inputs.size(1))  # [Batch, Steps, Features]\n",
    "\n",
    "        spk_in = poisson_encode(inputs, num_steps)\n",
    "        spk_in = spk_in.permute(1, 0, 2, 3)           # (num_steps, batch, steps, features)\n",
    "        spk_in = spk_in.reshape(spk_in.size(0), spk_in.size(1), -1)  # (num_steps, batch, steps*features)\n",
    "\n",
    "        spk2_rec = net(spk_in)                          # (time, batch, classes)\n",
    "        spk_count = spk2_rec.sum(0) / num_steps         # ✅ FIXED: average over steps\n",
    "\n",
    "        loss = criterion(spk_count, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        correct += (spk_count.argmax(1) == targets).sum().item()\n",
    "        total_spikes += spk2_rec.sum().item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    train_acc = correct / len(train_loader.dataset)\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    avg_spike_rate = total_spikes / (len(train_loader.dataset) * num_steps * hidden_size)\n",
    "\n",
    "    # --- Validation ---\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            inputs = inputs / inputs.max()\n",
    "            inputs = inputs.view(inputs.size(0), inputs.size(2), inputs.size(1))\n",
    "\n",
    "            spk_in = poisson_encode(inputs, num_steps)\n",
    "            spk_in = spk_in.permute(1, 0, 2, 3)\n",
    "            spk_in = spk_in.reshape(spk_in.size(0), spk_in.size(1), -1)\n",
    "\n",
    "            spk2_rec = net(spk_in)\n",
    "            spk_count = spk2_rec.sum(0) / num_steps\n",
    "\n",
    "            correct += (spk_count.argmax(1) == targets).sum().item()\n",
    "\n",
    "    val_acc = correct / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}, Spike Rate: {avg_spike_rate:.4f}, Accuracy: {train_acc:.4f}, Validation Accuracy: {val_acc:.4f}, Total Spikes: {total_spikes:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
