{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import norse.torch as norse\n",
    "import numpy as np\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "learning_rate = 0.01\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader():\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    train_dataset = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
    "    test_dataset = datasets.MNIST(root=\"./data\", train=False, transform=transform, download=True)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 256)\n",
    "        self.lif1 = norse.LIFCell()\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        self.lif2 = norse.LIFCell()\n",
    "    \n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, _, _, _ = x.shape\n",
    "        x = x.view(batch_size, -1)  # Flatten the input\n",
    "        spk, mem = self.lif1(self.fc1(x))\n",
    "        spk, mem = self.lif2(self.fc2(spk))\n",
    "        return spk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hebbian Learning Rule\n",
    "class HebbianLearning:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "    \n",
    "    def update_weights(self, weights, inputs, outputs):\n",
    "        if isinstance(inputs, norse.LIFFeedForwardState):\n",
    "            inputs = inputs.v  # Extract membrane potential if LIFFeedForwardState\n",
    "        if isinstance(outputs, norse.LIFFeedForwardState):\n",
    "            outputs = outputs.v  # Extract membrane potential if LIFFeedForwardState\n",
    "        \n",
    "        # Ensure tensors have correct dimensions\n",
    "        batch_size = inputs.shape[0]\n",
    "        inputs = inputs.view(batch_size, -1)  # Reshape inputs (64, 784)\n",
    "        outputs = outputs.view(batch_size, -1)  # Reshape outputs (64, 256)\n",
    "        \n",
    "        # Compute batch-wise Hebbian weight update\n",
    "        delta_w = self.lr * torch.mm(outputs.T, inputs) / batch_size  # (256, 784)\n",
    "        \n",
    "        # Ensure weights match the expected shape (256, 784)\n",
    "        if weights.shape != delta_w.shape:\n",
    "            raise RuntimeError(f\"Shape mismatch: weights={weights.shape}, delta_w={delta_w.shape}\")\n",
    "        \n",
    "        return weights + delta_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer-Based Optimization\n",
    "class TransformerOptimizer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(TransformerOptimizer, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=input_dim, num_heads=2)\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add sequence dimension\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "        return self.fc(attn_output.squeeze(1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified SNN with Bio-Transformer Learning (BTL)\n",
    "class BTL_SNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BTL_SNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 256)\n",
    "        self.lif1 = norse.LIFCell()\n",
    "        self.hebbian = HebbianLearning(lr=0.005)\n",
    "        self.transformer = TransformerOptimizer(256, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        self.lif2 = norse.LIFCell()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, _, _, _ = x.shape\n",
    "        x = x.view(batch_size, -1)  # Flatten the input\n",
    "        x = self.fc1(x)\n",
    "        spk, mem = self.lif1(x)\n",
    "        x = self.hebbian.update_weights(x, spk, mem)\n",
    "        x = self.transformer(x)\n",
    "        spk, mem = self.lif2(self.fc2(x))\n",
    "        return spk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(model, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Shape mismatch: weights=torch.Size([64, 256]), delta_w=torch.Size([256, 256])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Load data and train\u001b[39;00m\n\u001b[0;32m     10\u001b[0m train_loader, test_loader \u001b[38;5;241m=\u001b[39m get_data_loader()\n\u001b[1;32m---> 11\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43msnn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, criterion)\u001b[0m\n\u001b[0;32m      7\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 9\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     11\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Snn's\\sn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[18], line 17\u001b[0m, in \u001b[0;36mBTL_SNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x)\n\u001b[0;32m     16\u001b[0m spk, mem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlif1(x)\n\u001b[1;32m---> 17\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhebbian\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(x)\n\u001b[0;32m     19\u001b[0m spk, mem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlif2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n",
      "Cell \u001b[1;32mIn[16], line 22\u001b[0m, in \u001b[0;36mHebbianLearning.update_weights\u001b[1;34m(self, weights, inputs, outputs)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Ensure weights match the expected shape (256, 784)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m delta_w\u001b[38;5;241m.\u001b[39mshape:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape mismatch: weights=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweights\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, delta_w=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdelta_w\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m weights \u001b[38;5;241m+\u001b[39m delta_w\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Shape mismatch: weights=torch.Size([64, 256]), delta_w=torch.Size([256, 256])"
     ]
    }
   ],
   "source": [
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize models and training parameters\n",
    "snn_model = BTL_SNN().to(device)\n",
    "optimizer = optim.Adam(snn_model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Load data and train\n",
    "train_loader, test_loader = get_data_loader()\n",
    "train(snn_model, train_loader, optimizer, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
